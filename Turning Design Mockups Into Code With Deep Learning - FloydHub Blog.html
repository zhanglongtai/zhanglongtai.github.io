<!DOCTYPE html>
<!-- saved from url=(0078)https://blog.floydhub.com/turning-design-mockups-into-code-with-deep-learning/ -->
<html><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta http-equiv="x-ua-compatible" content="ie=edge"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><link rel="preload" href="./Turning Design Mockups Into Code With Deep Learning - FloydHub Blog_files/component---src-layouts-index-js-189bdf178e4571b8940a.js.下载" as="script"><link rel="preload" href="./Turning Design Mockups Into Code With Deep Learning - FloydHub Blog_files/component---src-templates-blog-post-js-5703835bb5cb9f72cab8.js.下载" as="script"><link rel="preload" href="./Turning Design Mockups Into Code With Deep Learning - FloydHub Blog_files/path---turning-design-mockups-into-code-with-deep-learning-4ddf6fbfa3a953649ebc.js.下载" as="script"><link rel="preload" href="./Turning Design Mockups Into Code With Deep Learning - FloydHub Blog_files/app-9a89fcc927a69b003059.js.下载" as="script"><link rel="preload" href="./Turning Design Mockups Into Code With Deep Learning - FloydHub Blog_files/commons-cfe08c15100186618874.js.下载" as="script"><script async="" src="./Turning Design Mockups Into Code With Deep Learning - FloydHub Blog_files/analytics.js.下载"></script><script id="webpack-manifest">/*<![CDATA[*/window.webpackManifest={"231608221292675":"app-9a89fcc927a69b003059.js","107818501498521":"component---src-templates-blog-post-js-5703835bb5cb9f72cab8.js","117114200232557":"component---src-pages-2017-08-02-react-post-index-js-1921a4106898dfc7f75a.js","162898551421021":"component---src-pages-404-js-1487be6d24bcb676f4d4.js","35783957827783":"component---src-pages-index-js-ad075a657419435f2b16.js","60335399758886":"path----557518bd178906f8d58a.js","134040251569668":"path---turning-design-mockups-into-code-with-deep-learning-4ddf6fbfa3a953649ebc.js","6535468297957":"path---generating-six-pack-abs-with-tensorflow-e84a3259f202436b2542.js","1933940279766":"path---colorizing-b-w-photos-with-neural-networks-f6d0fec402f1db8894b5.js","175602578996000":"path---building-your-first-convnet-d56a82665000e746a223.js","7612347052532":"path---creating-datasets-from-public-urls-df8355b853dc0ce0df34.js","240831556989227":"path---getting-started-with-deep-learning-on-floydhub-f585b07405a768d4ec7f.js","272489005924775":"path---coding-the-history-of-deep-learning-283a0e95a4a9bae4e116.js","252031521148904":"path---should-i-buy-my-own-gpus-for-deep-learning-144254c14f88b052a4e7.js","26199422862855":"path---my-first-weekend-of-deep-learning-141e5ce816486f27fbd7.js","266662989253392":"path---hello-readme-files-8e577884b304568c0321.js","19345689268867":"path---checkpointing-tutorial-for-tensorflow-keras-and-pytorch-66d92f24f160794488f7.js","148962119076747":"path---tensorboard-on-floydhub-a0d2bebcf26119167dab.js","56074389557885":"path---benchmarking-floydhub-instances-742a44d4b9c6d4ae673c.js","84955798127291":"path---react-post-0fd2628baf217fb7163a.js","273232040093931":"path---restart-jupyter-notebook-workflow-a643b869dead7c1e8cb6.js","254022195166212":"path---404-a0e39f21c11f6a62c5ab.js","142629428675168":"path---index-baa852a671877ef9dee5.js","178698757827068":"path---404-html-a0e39f21c11f6a62c5ab.js","34314898023162":"path---2017-08-02-react-post-a0e39f21c11f6a62c5ab.js","114276838955818":"component---src-layouts-index-js-189bdf178e4571b8940a.js"}/*]]>*/</script><title data-react-helmet="true">Turning Design Mockups Into Code With Deep Learning - FloydHub Blog</title><link data-react-helmet="true" rel="shortcut icon" href="https://blog.floydhub.com/img/favicon.ico"><meta data-react-helmet="true" name="description" content="FloydHub - Deep Learning Platform - Cloud GPU"><meta data-react-helmet="true" name="keywords" content="deep learning, AI, cloud GPU, artificial intellience, machine learning, floydhub"><link rel="alternate" type="application/rss+xml" href="https://blog.floydhub.com/rss.xml"><script>/*<![CDATA[*/!function(e,t,r){function n(){for(;d[0]&&"loaded"==d[0][f];)c=d.shift(),c[o]=!i.parentNode.insertBefore(c,i)}for(var s,a,c,d=[],i=e.scripts[0],o="onreadystatechange",f="readyState";s=r.shift();)a=e.createElement(t),"async"in i?(a.async=!1,e.head.appendChild(a)):i[f]?(d.push(a),a[o]=n):e.write("<"+t+' src="'+s+'" defer></'+t+">"),a.src=s}(document,"script",["/commons-cfe08c15100186618874.js","/app-9a89fcc927a69b003059.js","/path---turning-design-mockups-into-code-with-deep-learning-4ddf6fbfa3a953649ebc.js","/component---src-templates-blog-post-js-5703835bb5cb9f72cab8.js","/component---src-layouts-index-js-189bdf178e4571b8940a.js"])/*]]>*/</script><script src="./Turning Design Mockups Into Code With Deep Learning - FloydHub Blog_files/commons-cfe08c15100186618874.js.下载"></script><script src="./Turning Design Mockups Into Code With Deep Learning - FloydHub Blog_files/app-9a89fcc927a69b003059.js.下载"></script><script src="./Turning Design Mockups Into Code With Deep Learning - FloydHub Blog_files/path---turning-design-mockups-into-code-with-deep-learning-4ddf6fbfa3a953649ebc.js.下载"></script><script src="./Turning Design Mockups Into Code With Deep Learning - FloydHub Blog_files/component---src-templates-blog-post-js-5703835bb5cb9f72cab8.js.下载"></script><script src="./Turning Design Mockups Into Code With Deep Learning - FloydHub Blog_files/component---src-layouts-index-js-189bdf178e4571b8940a.js.下载"></script><style id="gatsby-inlined-css">html{font-family:Roboto,sans-serif!important;-ms-text-size-adjust:100%;-webkit-text-size-adjust:100%}body{margin:0;background-color:#fff;color:#4c4c4c}.post:hover{border:1px solid tomato}article,aside,details,figcaption,figure,footer,header,main,menu,nav,section,summary{display:block}audio,canvas,progress,video{display:inline-block}audio:not([controls]){display:none;height:0}progress{vertical-align:baseline}[hidden],template{display:none}a{background-color:transparent;-webkit-text-decoration-skip:objects;text-decoration:none;color:#007cdc}a:active,a:hover{outline-width:0;color:#1a77c0}abbr[title]{border-bottom:none;text-decoration:underline;text-decoration:underline dotted}b,strong{font-weight:inherit;font-weight:bolder}dfn{font-style:italic}h1{font-size:2em;margin:.67em 0}mark{background-color:#ff0;color:#000}small{font-size:80%}sub,sup{font-size:75%;line-height:0;position:relative;vertical-align:baseline}sub{bottom:-.25em}sup{top:-.5em}img{border-style:none}svg:not(:root){overflow:hidden}code,kbd,pre,samp{font-family:monospace,monospace;font-size:1em}figure{margin:1em 40px}hr{box-sizing:content-box;height:0;overflow:visible}button,input,optgroup,select,textarea{font:inherit;margin:0}optgroup{font-weight:700}button,input{overflow:visible}button,select{text-transform:none}[type=reset],[type=submit],button,html [type=button]{-webkit-appearance:button}[type=button]::-moz-focus-inner,[type=reset]::-moz-focus-inner,[type=submit]::-moz-focus-inner,button::-moz-focus-inner{border-style:none;padding:0}[type=button]:-moz-focusring,[type=reset]:-moz-focusring,[type=submit]:-moz-focusring,button:-moz-focusring{outline:1px dotted ButtonText}fieldset{border:1px solid silver;margin:0 2px;padding:.35em .625em .75em}legend{box-sizing:border-box;color:inherit;display:table;max-width:100%;padding:0;white-space:normal}textarea{overflow:auto}[type=checkbox],[type=radio]{box-sizing:border-box;padding:0}[type=number]::-webkit-inner-spin-button,[type=number]::-webkit-outer-spin-button{height:auto}[type=search]{-webkit-appearance:textfield;outline-offset:-2px}[type=search]::-webkit-search-cancel-button,[type=search]::-webkit-search-decoration{-webkit-appearance:none}::-webkit-input-placeholder{color:inherit;opacity:.54}::-webkit-file-upload-button{-webkit-appearance:button;font:inherit}html{font:112.5%/1.45em Roboto,sans-serif;box-sizing:border-box;overflow-y:scroll}*,:after,:before{box-sizing:inherit}body{color:#333;font-family:Roboto,sans-serif;font-weight:400;word-wrap:break-word;-webkit-font-kerning:normal;font-kerning:normal;-ms-font-feature-settings:"kern","liga","clig","calt";-webkit-font-feature-settings:"kern","liga","clig","calt";font-feature-settings:"kern","liga","clig","calt","kern"}img{max-width:100%;margin:0 0 .8rem;padding:0}h1{margin:2.5rem 0 1rem;font-weight:500;font-size:2.25rem;line-height:2.5rem}h1,h2{padding:0;font-family:Roboto,sans-serif;text-rendering:optimizeLegibility}h2{margin:2.5rem 0 .5rem;color:inherit;font-weight:400;font-size:1.75rem;line-height:2rem}h3{margin:2.5rem 0 1rem;font-size:1.5rem;line-height:2rem}h3,h4{padding:0;color:inherit;font-family:Roboto,sans-serif;font-weight:400;text-rendering:optimizeLegibility}h4{margin:2rem 0 1rem;font-size:1.25rem;line-height:1.35rem}h5{font-size:1.15rem}h5,h6{margin:2rem 0 1rem;padding:0;color:inherit;font-family:Roboto,sans-serif;font-weight:700;text-rendering:optimizeLegibility;line-height:1.25rem}h6{font-size:1rem}hgroup{margin:0 0 .5rem;padding:0}ul{line-height:1.9rem}ol,ul{margin:0 0 .5rem 1.45rem;padding:0;list-style-position:outside;list-style-image:none}dd,dl{margin:0 0 .5rem}dd,dl,p{padding:0}p{margin:0 0 1.25rem;line-height:1.9rem;font-size:1rem}figure{padding:0}figure,pre{margin:0 0 1.45rem}pre{padding:0;font-size:.85rem;line-height:1.42;background:rgba(0,0,0,.04);border-radius:3px;overflow:auto;word-wrap:normal;padding:1.45rem}table{font-size:1rem;line-height:1.45rem;border-collapse:collapse;width:100%}fieldset,table{margin:0 0 1.45rem;padding:0}blockquote{margin:0 1.45rem 1.45rem;padding:0}form,iframe,noscript{margin:0 0 1.45rem;padding:0}hr{margin:0 0 calc(1.45rem - 1px);padding:0;background:rgba(0,0,0,.2);border:none;height:1px}address{margin:0 0 1.45rem;padding:0}b,dt,strong,th{font-weight:700}li{margin-bottom:.725rem;font-size:1rem}ol li,ul li{padding-left:0;font-size:1rem}li>ol,li>ul{margin-left:1.45rem;margin-bottom:.725rem;margin-top:.725rem;font-size:1rem}blockquote :last-child,li :last-child,p :last-child{margin-bottom:0}li>p{margin-bottom:.725rem}code,kbd,samp{font-size:.85rem;line-height:1.45rem}abbr,abbr[title],acronym{border-bottom:1px dotted rgba(0,0,0,.5);cursor:help}abbr[title]{text-decoration:none}td,th,thead{text-align:left}td,th{border-bottom:1px solid rgba(0,0,0,.12);font-feature-settings:"tnum";-moz-font-feature-settings:"tnum";-ms-font-feature-settings:"tnum";-webkit-font-feature-settings:"tnum";padding:.725rem .96667rem calc(.725rem - 1px)}td:first-child,th:first-child{padding-left:0}td:last-child,th:last-child{padding-right:0}code,tt{background-color:rgba(0,0,0,.04);border-radius:3px;font-family:SFMono-Regular,Consolas,Roboto Mono,Droid Sans Mono,Liberation Mono,Menlo,Courier,monospace;padding:0;padding-top:.2em;padding-bottom:.2em}pre code{background:none;line-height:1.42}code:after,code:before,tt:after,tt:before{letter-spacing:-.2em;content:" "}pre code:after,pre code:before,pre tt:after,pre tt:before{content:""}@media only screen and (max-width:480px){html{font-size:100%}}.indexPost-left{width:55%}.indexPost-right{display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-pack:center;-ms-flex-pack:center;justify-content:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-orient:vertical;-webkit-box-direction:normal;-ms-flex-direction:column;flex-direction:column}@media only screen and (max-width:790px){.indexPost-left{width:100%}.alert-bar,.twitter-text{display:none}}@font-face{font-family:Roboto;font-style:normal;font-display:swap;font-weight:100;src:local("Roboto Thin "),local("Roboto-Thin"),url(/static/roboto-latin-100.987b8457.woff2) format("woff2"),url(/static/roboto-latin-100.e9dbbe8a.woff) format("woff")}@font-face{font-family:Roboto;font-style:italic;font-display:swap;font-weight:100;src:local("Roboto Thin italic"),local("Roboto-Thinitalic"),url(/static/roboto-latin-100italic.6232f43d.woff2) format("woff2"),url(/static/roboto-latin-100italic.d704bb3d.woff) format("woff")}@font-face{font-family:Roboto;font-style:normal;font-display:swap;font-weight:300;src:local("Roboto Light "),local("Roboto-Light"),url(/static/roboto-latin-300.55536c8e.woff2) format("woff2"),url(/static/roboto-latin-300.a1471d1d.woff) format("woff")}@font-face{font-family:Roboto;font-style:italic;font-display:swap;font-weight:300;src:local("Roboto Light italic"),local("Roboto-Lightitalic"),url(/static/roboto-latin-300italic.d69924b9.woff2) format("woff2"),url(/static/roboto-latin-300italic.210a7c78.woff) format("woff")}@font-face{font-family:Roboto;font-style:normal;font-display:swap;font-weight:400;src:local("Roboto Regular "),local("Roboto-Regular"),url(/static/roboto-latin-400.5d4aeb4e.woff2) format("woff2"),url(/static/roboto-latin-400.bafb105b.woff) format("woff")}@font-face{font-family:Roboto;font-style:italic;font-display:swap;font-weight:400;src:local("Roboto Regular italic"),local("Roboto-Regularitalic"),url(/static/roboto-latin-400italic.d8bcbe72.woff2) format("woff2"),url(/static/roboto-latin-400italic.9680d5a0.woff) format("woff")}@font-face{font-family:Roboto;font-style:normal;font-display:swap;font-weight:500;src:local("Roboto Medium "),local("Roboto-Medium"),url(/static/roboto-latin-500.28546717.woff2) format("woff2"),url(/static/roboto-latin-500.de8b7431.woff) format("woff")}@font-face{font-family:Roboto;font-style:italic;font-display:swap;font-weight:500;src:local("Roboto Medium italic"),local("Roboto-Mediumitalic"),url(/static/roboto-latin-500italic.510dec37.woff2) format("woff2"),url(/static/roboto-latin-500italic.ffcc050b.woff) format("woff")}@font-face{font-family:Roboto;font-style:normal;font-display:swap;font-weight:700;src:local("Roboto Bold "),local("Roboto-Bold"),url(/static/roboto-latin-700.037d8304.woff2) format("woff2"),url(/static/roboto-latin-700.cf6613d1.woff) format("woff")}@font-face{font-family:Roboto;font-style:italic;font-display:swap;font-weight:700;src:local("Roboto Bold italic"),local("Roboto-Bolditalic"),url(/static/roboto-latin-700italic.010c1aee.woff2) format("woff2"),url(/static/roboto-latin-700italic.846d1890.woff) format("woff")}@font-face{font-family:Roboto;font-style:normal;font-display:swap;font-weight:900;src:local("Roboto Black "),local("Roboto-Black"),url(/static/roboto-latin-900.19b7a0ad.woff2) format("woff2"),url(/static/roboto-latin-900.8c2ade50.woff) format("woff")}@font-face{font-family:Roboto;font-style:italic;font-display:swap;font-weight:900;src:local("Roboto Black italic"),local("Roboto-Blackitalic"),url(/static/roboto-latin-900italic.7b770d6c.woff2) format("woff2"),url(/static/roboto-latin-900italic.bc833e72.woff) format("woff")}code[class*=language-],pre[class*=language-]{color:#f8f8f2;background:none;text-shadow:0 1px rgba(0,0,0,.3);font-family:Consolas,Monaco,Andale Mono,Ubuntu Mono,monospace;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;word-wrap:normal;line-height:1.5;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-hyphens:none;-ms-hyphens:none;hyphens:none}pre[class*=language-]{padding:1em;margin:.5em 0;overflow:auto;border-radius:.3em}:not(pre)>code[class*=language-],pre[class*=language-]{background:#272822}:not(pre)>code[class*=language-]{padding:.1em;border-radius:.3em;white-space:normal}.token.cdata,.token.comment,.token.doctype,.token.prolog{color:#708090}.token.punctuation{color:#f8f8f2}.namespace{opacity:.7}.token.constant,.token.deleted,.token.property,.token.symbol,.token.tag{color:#f92672}.token.boolean,.token.number{color:#ae81ff}.token.attr-name,.token.builtin,.token.char,.token.inserted,.token.selector,.token.string{color:#a6e22e}.language-css .token.string,.style .token.string,.token.entity,.token.operator,.token.url,.token.variable{color:#f8f8f2}.token.atrule,.token.attr-value,.token.function{color:#e6db74}.token.keyword{color:#66d9ef}.token.important,.token.regex{color:#fd971f}.token.bold,.token.important{font-weight:700}.token.italic{font-style:italic}.token.entity{cursor:help}@font-face{font-family:KaTeX_AMS;src:url(/static/KaTeX_AMS-Regular.672c9619.eot);src:url(/static/KaTeX_AMS-Regular.672c9619.eot#iefix) format("embedded-opentype"),url(/static/KaTeX_AMS-Regular.f4c3270b.woff2) format("woff2"),url(/static/KaTeX_AMS-Regular.e78f217c.woff) format("woff"),url(/static/KaTeX_AMS-Regular.9971d270.ttf) format("truetype");font-weight:400;font-style:normal}@font-face{font-family:KaTeX_Caligraphic;src:url(/static/KaTeX_Caligraphic-Bold.3c3fce5e.eot);src:url(/static/KaTeX_Caligraphic-Bold.3c3fce5e.eot#iefix) format("embedded-opentype"),url(/static/KaTeX_Caligraphic-Bold.a2e05225.woff2) format("woff2"),url(/static/KaTeX_Caligraphic-Bold.bac61997.woff) format("woff"),url(/static/KaTeX_Caligraphic-Bold.743b42a3.ttf) format("truetype");font-weight:700;font-style:normal}@font-face{font-family:KaTeX_Caligraphic;src:url(/static/KaTeX_Caligraphic-Regular.a0ba2817.eot);src:url(/static/KaTeX_Caligraphic-Regular.a0ba2817.eot#iefix) format("embedded-opentype"),url(/static/KaTeX_Caligraphic-Regular.479a68ec.woff2) format("woff2"),url(/static/KaTeX_Caligraphic-Regular.a64e1342.woff) format("woff"),url(/static/KaTeX_Caligraphic-Regular.244db27f.ttf) format("truetype");font-weight:400;font-style:normal}@font-face{font-family:KaTeX_Fraktur;src:url(/static/KaTeX_Fraktur-Bold.2b4454d6.eot);src:url(/static/KaTeX_Fraktur-Bold.2b4454d6.eot#iefix) format("embedded-opentype"),url(/static/KaTeX_Fraktur-Bold.8e5f883e.woff2) format("woff2"),url(/static/KaTeX_Fraktur-Bold.0a0aa194.woff) format("woff"),url(/static/KaTeX_Fraktur-Bold.ad26cc83.ttf) format("truetype");font-weight:700;font-style:normal}@font-face{font-family:KaTeX_Fraktur;src:url(/static/KaTeX_Fraktur-Regular.dc81eae9.eot);src:url(/static/KaTeX_Fraktur-Regular.dc81eae9.eot#iefix) format("embedded-opentype"),url(/static/KaTeX_Fraktur-Regular.ae2b6f43.woff2) format("woff2"),url(/static/KaTeX_Fraktur-Regular.f980ca72.woff) format("woff"),url(/static/KaTeX_Fraktur-Regular.d459632e.ttf) format("truetype");font-weight:400;font-style:normal}@font-face{font-family:KaTeX_Main;src:url(/static/KaTeX_Main-Bold.d327c210.eot);src:url(/static/KaTeX_Main-Bold.d327c210.eot#iefix) format("embedded-opentype"),url(/static/KaTeX_Main-Bold.83f8b326.woff2) format("woff2"),url(/static/KaTeX_Main-Bold.d8a629d2.woff) format("woff"),url(/static/KaTeX_Main-Bold.e69b9513.ttf) format("truetype");font-weight:700;font-style:normal}@font-face{font-family:KaTeX_Main;src:url(/static/KaTeX_Main-Italic.2702ac35.eot);src:url(/static/KaTeX_Main-Italic.2702ac35.eot#iefix) format("embedded-opentype"),url(/static/KaTeX_Main-Italic.07510ed0.woff2) format("woff2"),url(/static/KaTeX_Main-Italic.8dd42e02.woff) format("woff"),url(/static/KaTeX_Main-Italic.1b226149.ttf) format("truetype");font-weight:400;font-style:italic}@font-face{font-family:KaTeX_Main;src:url(/static/KaTeX_Main-Regular.31ec4506.eot);src:url(/static/KaTeX_Main-Regular.31ec4506.eot#iefix) format("embedded-opentype"),url(/static/KaTeX_Main-Regular.bd652252.woff2) format("woff2"),url(/static/KaTeX_Main-Regular.2dffc875.woff) format("woff"),url(/static/KaTeX_Main-Regular.d9162dfe.ttf) format("truetype");font-weight:400;font-style:normal}@font-face{font-family:KaTeX_Math;src:url(/static/KaTeX_Math-Italic.031026c4.eot);src:url(/static/KaTeX_Math-Italic.031026c4.eot#iefix) format("embedded-opentype"),url(/static/KaTeX_Math-Italic.afeebb76.woff2) format("woff2"),url(/static/KaTeX_Math-Italic.da586018.woff) format("woff"),url(/static/KaTeX_Math-Italic.55fbb3ac.ttf) format("truetype");font-weight:400;font-style:italic}@font-face{font-family:KaTeX_SansSerif;src:url(/static/KaTeX_SansSerif-Regular.a3319b73.eot);src:url(/static/KaTeX_SansSerif-Regular.a3319b73.eot#iefix) format("embedded-opentype"),url(/static/KaTeX_SansSerif-Regular.7d5fa3e2.woff2) format("woff2"),url(/static/KaTeX_SansSerif-Regular.48c7df6f.woff) format("woff"),url(/static/KaTeX_SansSerif-Regular.8075d14a.ttf) format("truetype");font-weight:400;font-style:normal}@font-face{font-family:KaTeX_Script;src:url(/static/KaTeX_Script-Regular.cf8394e8.eot);src:url(/static/KaTeX_Script-Regular.cf8394e8.eot#iefix) format("embedded-opentype"),url(/static/KaTeX_Script-Regular.c472b570.woff2) format("woff2"),url(/static/KaTeX_Script-Regular.5acb381b.woff) format("woff"),url(/static/KaTeX_Script-Regular.abb12fc2.ttf) format("truetype");font-weight:400;font-style:normal}@font-face{font-family:KaTeX_Size1;src:url(/static/KaTeX_Size1-Regular.5438d9d4.eot);src:url(/static/KaTeX_Size1-Regular.5438d9d4.eot#iefix) format("embedded-opentype"),url(/static/KaTeX_Size1-Regular.feed6c70.woff2) format("woff2"),url(/static/KaTeX_Size1-Regular.bdd0d5e0.woff) format("woff"),url(/static/KaTeX_Size1-Regular.8cc60fd5.ttf) format("truetype");font-weight:400;font-style:normal}@font-face{font-family:KaTeX_Size2;src:url(/static/KaTeX_Size2-Regular.1f5c2abf.eot);src:url(/static/KaTeX_Size2-Regular.1f5c2abf.eot#iefix) format("embedded-opentype"),url(/static/KaTeX_Size2-Regular.8a86a0af.woff2) format("woff2"),url(/static/KaTeX_Size2-Regular.fd67fb35.woff) format("woff"),url(/static/KaTeX_Size2-Regular.5976fffd.ttf) format("truetype");font-weight:400;font-style:normal}@font-face{font-family:KaTeX_Size3;src:url(/static/KaTeX_Size3-Regular.1a6c0d68.eot);src:url(/static/KaTeX_Size3-Regular.1a6c0d68.eot#iefix) format("embedded-opentype"),url(/static/KaTeX_Size3-Regular.2c1ea030.woff2) format("woff2"),url(/static/KaTeX_Size3-Regular.943c94f8.woff) format("woff"),url(/static/KaTeX_Size3-Regular.e929f5d9.ttf) format("truetype");font-weight:400;font-style:normal}@font-face{font-family:KaTeX_Size4;src:url(/static/KaTeX_Size4-Regular.5a3cee2b.eot);src:url(/static/KaTeX_Size4-Regular.5a3cee2b.eot#iefix) format("embedded-opentype"),url(/static/KaTeX_Size4-Regular.680d35e3.woff2) format("woff2"),url(/static/KaTeX_Size4-Regular.68537743.woff) format("woff"),url(/static/KaTeX_Size4-Regular.81ab95e4.ttf) format("truetype");font-weight:400;font-style:normal}@font-face{font-family:KaTeX_Typewriter;src:url(/static/KaTeX_Typewriter-Regular.b2e94149.eot);src:url(/static/KaTeX_Typewriter-Regular.b2e94149.eot#iefix) format("embedded-opentype"),url(/static/KaTeX_Typewriter-Regular.8a6d8ed8.woff2) format("woff2"),url(/static/KaTeX_Typewriter-Regular.3e9e27f0.woff) format("woff"),url(/static/KaTeX_Typewriter-Regular.29017475.ttf) format("truetype");font-weight:400;font-style:normal}.katex-display{display:block;margin:1em 0;text-align:center}.katex-display>.katex{display:inline-block;text-align:left;text-align:initial}.katex{font:400 1.21em KaTeX_Main,Times New Roman,serif;line-height:1.2;white-space:nowrap;text-indent:0}.katex .katex-html{display:inline-block}.katex .katex-mathml{position:absolute;clip:rect(1px,1px,1px,1px);padding:0;border:0;height:1px;width:1px;overflow:hidden}.katex .base,.katex .strut{display:inline-block}.katex .mathrm{font-style:normal}.katex .mathit,.katex .textit{font-style:italic}.katex .mathit{font-family:KaTeX_Math}.katex .mathbf{font-family:KaTeX_Main;font-weight:700}.katex .amsrm,.katex .mathbb{font-family:KaTeX_AMS}.katex .mathcal{font-family:KaTeX_Caligraphic}.katex .mathfrak{font-family:KaTeX_Fraktur}.katex .mathtt{font-family:KaTeX_Typewriter}.katex .mathscr{font-family:KaTeX_Script}.katex .mathsf{font-family:KaTeX_SansSerif}.katex .mainit{font-family:KaTeX_Main;font-style:italic}.katex .mord+.mop{margin-left:.16667em}.katex .mord+.mbin{margin-left:.22222em}.katex .mord+.mrel{margin-left:.27778em}.katex .mop+.mop,.katex .mop+.mord,.katex .mord+.minner{margin-left:.16667em}.katex .mop+.mrel{margin-left:.27778em}.katex .mop+.minner{margin-left:.16667em}.katex .mbin+.minner,.katex .mbin+.mop,.katex .mbin+.mopen,.katex .mbin+.mord{margin-left:.22222em}.katex .mrel+.minner,.katex .mrel+.mop,.katex .mrel+.mopen,.katex .mrel+.mord{margin-left:.27778em}.katex .mclose+.mop{margin-left:.16667em}.katex .mclose+.mbin{margin-left:.22222em}.katex .mclose+.mrel{margin-left:.27778em}.katex .mclose+.minner,.katex .minner+.mop,.katex .minner+.mord,.katex .mpunct+.mclose,.katex .mpunct+.minner,.katex .mpunct+.mop,.katex .mpunct+.mopen,.katex .mpunct+.mord,.katex .mpunct+.mpunct,.katex .mpunct+.mrel{margin-left:.16667em}.katex .minner+.mbin{margin-left:.22222em}.katex .minner+.mrel{margin-left:.27778em}.katex .minner+.minner,.katex .minner+.mopen,.katex .minner+.mpunct{margin-left:.16667em}.katex .mbin.mtight,.katex .mclose.mtight,.katex .minner.mtight,.katex .mop.mtight,.katex .mopen.mtight,.katex .mord.mtight,.katex .mpunct.mtight,.katex .mrel.mtight{margin-left:0}.katex .mclose+.mop.mtight,.katex .minner+.mop.mtight,.katex .mop+.mop.mtight,.katex .mop+.mord.mtight,.katex .mord+.mop.mtight{margin-left:.16667em}.katex .reset-textstyle.textstyle{font-size:1em}.katex .reset-textstyle.scriptstyle{font-size:.7em}.katex .reset-textstyle.scriptscriptstyle{font-size:.5em}.katex .reset-scriptstyle.textstyle{font-size:1.42857em}.katex .reset-scriptstyle.scriptstyle{font-size:1em}.katex .reset-scriptstyle.scriptscriptstyle{font-size:.71429em}.katex .reset-scriptscriptstyle.textstyle{font-size:2em}.katex .reset-scriptscriptstyle.scriptstyle{font-size:1.4em}.katex .reset-scriptscriptstyle.scriptscriptstyle{font-size:1em}.katex .style-wrap{position:relative}.katex .vlist{display:inline-block}.katex .vlist>span{display:block;height:0;position:relative}.katex .vlist>span>span{display:inline-block}.katex .vlist .baseline-fix{display:inline-table;table-layout:fixed}.katex .msupsub{text-align:left}.katex .mfrac>span>span{text-align:center}.katex .mfrac .frac-line{width:100%}.katex .mfrac .frac-line:before{border-bottom-style:solid;border-bottom-width:1px;content:"";display:block}.katex .mfrac .frac-line:after{border-bottom-style:solid;border-bottom-width:.04em;content:"";display:block;margin-top:-1px}.katex .mspace{display:inline-block}.katex .mspace.negativethinspace{margin-left:-.16667em}.katex .mspace.thinspace{width:.16667em}.katex .mspace.negativemediumspace{margin-left:-.22222em}.katex .mspace.mediumspace{width:.22222em}.katex .mspace.thickspace{width:.27778em}.katex .mspace.sixmuspace{width:.333333em}.katex .mspace.eightmuspace{width:.444444em}.katex .mspace.enspace{width:.5em}.katex .mspace.twelvemuspace{width:.666667em}.katex .mspace.quad{width:1em}.katex .mspace.qquad{width:2em}.katex .llap,.katex .rlap{width:0;position:relative}.katex .llap>.inner,.katex .rlap>.inner{position:absolute}.katex .llap>.fix,.katex .rlap>.fix{display:inline-block}.katex .llap>.inner{right:0}.katex .rlap>.inner{left:0}.katex .katex-logo .a{font-size:.75em;margin-left:-.32em;position:relative;top:-.2em}.katex .katex-logo .t{margin-left:-.23em}.katex .katex-logo .e{margin-left:-.1667em;position:relative;top:.2155em}.katex .katex-logo .x{margin-left:-.125em}.katex .rule{display:inline-block;border:0 solid;position:relative}.katex .overline .overline-line,.katex .underline .underline-line{width:100%}.katex .overline .overline-line:before,.katex .underline .underline-line:before{border-bottom-style:solid;border-bottom-width:1px;content:"";display:block}.katex .overline .overline-line:after,.katex .underline .underline-line:after{border-bottom-style:solid;border-bottom-width:.04em;content:"";display:block;margin-top:-1px}.katex .sqrt>.sqrt-sign{position:relative}.katex .sqrt .sqrt-line{width:100%}.katex .sqrt .sqrt-line:before{border-bottom-style:solid;border-bottom-width:1px;content:"";display:block}.katex .sqrt .sqrt-line:after{border-bottom-style:solid;border-bottom-width:.04em;content:"";display:block;margin-top:-1px}.katex .sqrt>.root{margin-left:.27777778em;margin-right:-.55555556em}.katex .fontsize-ensurer,.katex .sizing{display:inline-block}.katex .fontsize-ensurer.reset-size1.size1,.katex .sizing.reset-size1.size1{font-size:1em}.katex .fontsize-ensurer.reset-size1.size2,.katex .sizing.reset-size1.size2{font-size:1.4em}.katex .fontsize-ensurer.reset-size1.size3,.katex .sizing.reset-size1.size3{font-size:1.6em}.katex .fontsize-ensurer.reset-size1.size4,.katex .sizing.reset-size1.size4{font-size:1.8em}.katex .fontsize-ensurer.reset-size1.size5,.katex .sizing.reset-size1.size5{font-size:2em}.katex .fontsize-ensurer.reset-size1.size6,.katex .sizing.reset-size1.size6{font-size:2.4em}.katex .fontsize-ensurer.reset-size1.size7,.katex .sizing.reset-size1.size7{font-size:2.88em}.katex .fontsize-ensurer.reset-size1.size8,.katex .sizing.reset-size1.size8{font-size:3.46em}.katex .fontsize-ensurer.reset-size1.size9,.katex .sizing.reset-size1.size9{font-size:4.14em}.katex .fontsize-ensurer.reset-size1.size10,.katex .sizing.reset-size1.size10{font-size:4.98em}.katex .fontsize-ensurer.reset-size2.size1,.katex .sizing.reset-size2.size1{font-size:.71428571em}.katex .fontsize-ensurer.reset-size2.size2,.katex .sizing.reset-size2.size2{font-size:1em}.katex .fontsize-ensurer.reset-size2.size3,.katex .sizing.reset-size2.size3{font-size:1.14285714em}.katex .fontsize-ensurer.reset-size2.size4,.katex .sizing.reset-size2.size4{font-size:1.28571429em}.katex .fontsize-ensurer.reset-size2.size5,.katex .sizing.reset-size2.size5{font-size:1.42857143em}.katex .fontsize-ensurer.reset-size2.size6,.katex .sizing.reset-size2.size6{font-size:1.71428571em}.katex .fontsize-ensurer.reset-size2.size7,.katex .sizing.reset-size2.size7{font-size:2.05714286em}.katex .fontsize-ensurer.reset-size2.size8,.katex .sizing.reset-size2.size8{font-size:2.47142857em}.katex .fontsize-ensurer.reset-size2.size9,.katex .sizing.reset-size2.size9{font-size:2.95714286em}.katex .fontsize-ensurer.reset-size2.size10,.katex .sizing.reset-size2.size10{font-size:3.55714286em}.katex .fontsize-ensurer.reset-size3.size1,.katex .sizing.reset-size3.size1{font-size:.625em}.katex .fontsize-ensurer.reset-size3.size2,.katex .sizing.reset-size3.size2{font-size:.875em}.katex .fontsize-ensurer.reset-size3.size3,.katex .sizing.reset-size3.size3{font-size:1em}.katex .fontsize-ensurer.reset-size3.size4,.katex .sizing.reset-size3.size4{font-size:1.125em}.katex .fontsize-ensurer.reset-size3.size5,.katex .sizing.reset-size3.size5{font-size:1.25em}.katex .fontsize-ensurer.reset-size3.size6,.katex .sizing.reset-size3.size6{font-size:1.5em}.katex .fontsize-ensurer.reset-size3.size7,.katex .sizing.reset-size3.size7{font-size:1.8em}.katex .fontsize-ensurer.reset-size3.size8,.katex .sizing.reset-size3.size8{font-size:2.1625em}.katex .fontsize-ensurer.reset-size3.size9,.katex .sizing.reset-size3.size9{font-size:2.5875em}.katex .fontsize-ensurer.reset-size3.size10,.katex .sizing.reset-size3.size10{font-size:3.1125em}.katex .fontsize-ensurer.reset-size4.size1,.katex .sizing.reset-size4.size1{font-size:.55555556em}.katex .fontsize-ensurer.reset-size4.size2,.katex .sizing.reset-size4.size2{font-size:.77777778em}.katex .fontsize-ensurer.reset-size4.size3,.katex .sizing.reset-size4.size3{font-size:.88888889em}.katex .fontsize-ensurer.reset-size4.size4,.katex .sizing.reset-size4.size4{font-size:1em}.katex .fontsize-ensurer.reset-size4.size5,.katex .sizing.reset-size4.size5{font-size:1.11111111em}.katex .fontsize-ensurer.reset-size4.size6,.katex .sizing.reset-size4.size6{font-size:1.33333333em}.katex .fontsize-ensurer.reset-size4.size7,.katex .sizing.reset-size4.size7{font-size:1.6em}.katex .fontsize-ensurer.reset-size4.size8,.katex .sizing.reset-size4.size8{font-size:1.92222222em}.katex .fontsize-ensurer.reset-size4.size9,.katex .sizing.reset-size4.size9{font-size:2.3em}.katex .fontsize-ensurer.reset-size4.size10,.katex .sizing.reset-size4.size10{font-size:2.76666667em}.katex .fontsize-ensurer.reset-size5.size1,.katex .sizing.reset-size5.size1{font-size:.5em}.katex .fontsize-ensurer.reset-size5.size2,.katex .sizing.reset-size5.size2{font-size:.7em}.katex .fontsize-ensurer.reset-size5.size3,.katex .sizing.reset-size5.size3{font-size:.8em}.katex .fontsize-ensurer.reset-size5.size4,.katex .sizing.reset-size5.size4{font-size:.9em}.katex .fontsize-ensurer.reset-size5.size5,.katex .sizing.reset-size5.size5{font-size:1em}.katex .fontsize-ensurer.reset-size5.size6,.katex .sizing.reset-size5.size6{font-size:1.2em}.katex .fontsize-ensurer.reset-size5.size7,.katex .sizing.reset-size5.size7{font-size:1.44em}.katex .fontsize-ensurer.reset-size5.size8,.katex .sizing.reset-size5.size8{font-size:1.73em}.katex .fontsize-ensurer.reset-size5.size9,.katex .sizing.reset-size5.size9{font-size:2.07em}.katex .fontsize-ensurer.reset-size5.size10,.katex .sizing.reset-size5.size10{font-size:2.49em}.katex .fontsize-ensurer.reset-size6.size1,.katex .sizing.reset-size6.size1{font-size:.41666667em}.katex .fontsize-ensurer.reset-size6.size2,.katex .sizing.reset-size6.size2{font-size:.58333333em}.katex .fontsize-ensurer.reset-size6.size3,.katex .sizing.reset-size6.size3{font-size:.66666667em}.katex .fontsize-ensurer.reset-size6.size4,.katex .sizing.reset-size6.size4{font-size:.75em}.katex .fontsize-ensurer.reset-size6.size5,.katex .sizing.reset-size6.size5{font-size:.83333333em}.katex .fontsize-ensurer.reset-size6.size6,.katex .sizing.reset-size6.size6{font-size:1em}.katex .fontsize-ensurer.reset-size6.size7,.katex .sizing.reset-size6.size7{font-size:1.2em}.katex .fontsize-ensurer.reset-size6.size8,.katex .sizing.reset-size6.size8{font-size:1.44166667em}.katex .fontsize-ensurer.reset-size6.size9,.katex .sizing.reset-size6.size9{font-size:1.725em}.katex .fontsize-ensurer.reset-size6.size10,.katex .sizing.reset-size6.size10{font-size:2.075em}.katex .fontsize-ensurer.reset-size7.size1,.katex .sizing.reset-size7.size1{font-size:.34722222em}.katex .fontsize-ensurer.reset-size7.size2,.katex .sizing.reset-size7.size2{font-size:.48611111em}.katex .fontsize-ensurer.reset-size7.size3,.katex .sizing.reset-size7.size3{font-size:.55555556em}.katex .fontsize-ensurer.reset-size7.size4,.katex .sizing.reset-size7.size4{font-size:.625em}.katex .fontsize-ensurer.reset-size7.size5,.katex .sizing.reset-size7.size5{font-size:.69444444em}.katex .fontsize-ensurer.reset-size7.size6,.katex .sizing.reset-size7.size6{font-size:.83333333em}.katex .fontsize-ensurer.reset-size7.size7,.katex .sizing.reset-size7.size7{font-size:1em}.katex .fontsize-ensurer.reset-size7.size8,.katex .sizing.reset-size7.size8{font-size:1.20138889em}.katex .fontsize-ensurer.reset-size7.size9,.katex .sizing.reset-size7.size9{font-size:1.4375em}.katex .fontsize-ensurer.reset-size7.size10,.katex .sizing.reset-size7.size10{font-size:1.72916667em}.katex .fontsize-ensurer.reset-size8.size1,.katex .sizing.reset-size8.size1{font-size:.28901734em}.katex .fontsize-ensurer.reset-size8.size2,.katex .sizing.reset-size8.size2{font-size:.40462428em}.katex .fontsize-ensurer.reset-size8.size3,.katex .sizing.reset-size8.size3{font-size:.46242775em}.katex .fontsize-ensurer.reset-size8.size4,.katex .sizing.reset-size8.size4{font-size:.52023121em}.katex .fontsize-ensurer.reset-size8.size5,.katex .sizing.reset-size8.size5{font-size:.57803468em}.katex .fontsize-ensurer.reset-size8.size6,.katex .sizing.reset-size8.size6{font-size:.69364162em}.katex .fontsize-ensurer.reset-size8.size7,.katex .sizing.reset-size8.size7{font-size:.83236994em}.katex .fontsize-ensurer.reset-size8.size8,.katex .sizing.reset-size8.size8{font-size:1em}.katex .fontsize-ensurer.reset-size8.size9,.katex .sizing.reset-size8.size9{font-size:1.19653179em}.katex .fontsize-ensurer.reset-size8.size10,.katex .sizing.reset-size8.size10{font-size:1.43930636em}.katex .fontsize-ensurer.reset-size9.size1,.katex .sizing.reset-size9.size1{font-size:.24154589em}.katex .fontsize-ensurer.reset-size9.size2,.katex .sizing.reset-size9.size2{font-size:.33816425em}.katex .fontsize-ensurer.reset-size9.size3,.katex .sizing.reset-size9.size3{font-size:.38647343em}.katex .fontsize-ensurer.reset-size9.size4,.katex .sizing.reset-size9.size4{font-size:.43478261em}.katex .fontsize-ensurer.reset-size9.size5,.katex .sizing.reset-size9.size5{font-size:.48309179em}.katex .fontsize-ensurer.reset-size9.size6,.katex .sizing.reset-size9.size6{font-size:.57971014em}.katex .fontsize-ensurer.reset-size9.size7,.katex .sizing.reset-size9.size7{font-size:.69565217em}.katex .fontsize-ensurer.reset-size9.size8,.katex .sizing.reset-size9.size8{font-size:.83574879em}.katex .fontsize-ensurer.reset-size9.size9,.katex .sizing.reset-size9.size9{font-size:1em}.katex .fontsize-ensurer.reset-size9.size10,.katex .sizing.reset-size9.size10{font-size:1.20289855em}.katex .fontsize-ensurer.reset-size10.size1,.katex .sizing.reset-size10.size1{font-size:.20080321em}.katex .fontsize-ensurer.reset-size10.size2,.katex .sizing.reset-size10.size2{font-size:.2811245em}.katex .fontsize-ensurer.reset-size10.size3,.katex .sizing.reset-size10.size3{font-size:.32128514em}.katex .fontsize-ensurer.reset-size10.size4,.katex .sizing.reset-size10.size4{font-size:.36144578em}.katex .fontsize-ensurer.reset-size10.size5,.katex .sizing.reset-size10.size5{font-size:.40160643em}.katex .fontsize-ensurer.reset-size10.size6,.katex .sizing.reset-size10.size6{font-size:.48192771em}.katex .fontsize-ensurer.reset-size10.size7,.katex .sizing.reset-size10.size7{font-size:.57831325em}.katex .fontsize-ensurer.reset-size10.size8,.katex .sizing.reset-size10.size8{font-size:.69477912em}.katex .fontsize-ensurer.reset-size10.size9,.katex .sizing.reset-size10.size9{font-size:.8313253em}.katex .fontsize-ensurer.reset-size10.size10,.katex .sizing.reset-size10.size10{font-size:1em}.katex .delimsizing.size1{font-family:KaTeX_Size1}.katex .delimsizing.size2{font-family:KaTeX_Size2}.katex .delimsizing.size3{font-family:KaTeX_Size3}.katex .delimsizing.size4{font-family:KaTeX_Size4}.katex .delimsizing.mult .delim-size1>span{font-family:KaTeX_Size1}.katex .delimsizing.mult .delim-size4>span{font-family:KaTeX_Size4}.katex .nulldelimiter{display:inline-block;width:.12em}.katex .op-symbol{position:relative}.katex .op-symbol.small-op{font-family:KaTeX_Size1}.katex .op-symbol.large-op{font-family:KaTeX_Size2}.katex .accent>.vlist>span,.katex .op-limits>.vlist>span{text-align:center}.katex .accent .accent-body>span{width:0}.katex .accent .accent-body.accent-vec>span{position:relative;left:.326em}.katex .mtable .vertical-separator{display:inline-block;margin:0 -.025em;border-right:.05em solid #000}.katex .mtable .arraycolsep{display:inline-block}.katex .mtable .col-align-c>.vlist{text-align:center}.katex .mtable .col-align-l>.vlist{text-align:left}.katex .mtable .col-align-r>.vlist{text-align:right}</style></head><body><div id="___gatsby"><div data-reactroot="" data-reactid="1" data-react-checksum="-911428195"><!-- react-empty: 2 --><div style="background:rgb(33, 150, 243);" data-reactid="3"><div style="margin:0 auto;max-width:960px;padding:0.3rem 1.0875rem;display:flex;flex-direction:row;justify-content:space-between;align-items:center;" data-reactid="4"><div style="display:flex;flex-direction:row;align-items:center;padding-top:0.35rem;padding-bottom:0.35rem;" data-reactid="5"><a style="margin:0;display:flex;flex-direction:row;align-items:center;justify-content:flex-end;" href="https://www.floydhub.com/" data-reactid="6"><img src="./Turning Design Mockups Into Code With Deep Learning - FloydHub Blog_files/f-square.png" style="height:40px;width:40px;margin:0;" data-reactid="7"></a><h4 style="margin:0;padding-left:0.5rem;font-weight:400;" data-reactid="8"><a style="color:white;text-decoration:none;" href="https://blog.floydhub.com/" data-reactid="9">FloydHub Blog</a></h4></div><div style="display:flex;flex-direction:row;align-items:center;justify-content:flex-end;" data-reactid="10"><h6 style="margin:0px;" data-reactid="11"><a style="color:white;display:flex;align-items:right;font-size:0.95rem;font-weight:400;" href="https://www.twitter.com/FloydHub_" data-reactid="12"><svg fill="currentColor" preserveAspectRatio="xMidYMid meet" height="1em" width="1em" viewBox="0 0 40 40" style="vertical-align:middle;font-size:1.3rem;margin-right:0.25rem;" data-reactid="13"><g data-reactid="14"><path d="m37.7 9.1q-1.5 2.2-3.7 3.7 0.1 0.3 0.1 1 0 2.9-0.9 5.8t-2.6 5.5-4.1 4.7-5.7 3.3-7.2 1.2q-6.1 0-11.1-3.3 0.8 0.1 1.7 0.1 5 0 9-3-2.4-0.1-4.2-1.5t-2.6-3.5q0.8 0.1 1.4 0.1 1 0 1.9-0.3-2.5-0.5-4.1-2.5t-1.7-4.6v0q1.5 0.8 3.3 0.9-1.5-1-2.4-2.6t-0.8-3.4q0-2 0.9-3.7 2.7 3.4 6.6 5.4t8.3 2.2q-0.2-0.9-0.2-1.7 0-3 2.1-5.1t5.1-2.1q3.2 0 5.3 2.3 2.4-0.5 4.6-1.7-0.8 2.5-3.2 3.9 2.1-0.2 4.2-1.1z" data-reactid="15"></path></g></svg><span class="twitter-text" data-reactid="16">Follow FloydHub on Twitter</span></a></h6><a href="https://blog.floydhub.com/rss.xml" data-reactid="17"><img src="./Turning Design Mockups Into Code With Deep Learning - FloydHub Blog_files/rss.png" style="height:20px;width:20px;margin-left:1rem;margin-top:0.4rem;margin-bottom:0;" data-reactid="18"></a></div></div></div><div class="alert-bar" style="border-bottom:1px solid rgb(234, 236, 238);" data-reactid="19"><div style="margin:0 auto;max-width:960px;padding:0.3rem 1.0875rem;display:flex;flex-direction:row;justify-content:center;align-items:center;" data-reactid="20"><div style="height:3rem;display:flex;flex-direction:row;align-items:center;padding-top:0.35rem;padding-bottom:0.35rem;font-size:20px;font-weight:500;" data-reactid="21"><span data-reactid="22"><!-- react-text: 23 -->Get started with&nbsp;<!-- /react-text --><a href="https://www.floydhub.com/?utm_source=blog_banner&amp;utm_medium=blog&amp;utm_campaign=base_n17" data-reactid="24">deep learning on FloydHub</a><!-- react-text: 25 -->&nbsp;in minutes, or check out our&nbsp;<!-- /react-text --><a href="https://docs.floydhub.com/" data-reactid="26">docs</a></span></div></div></div><div style="margin-left:auto;margin-right:auto;margin-top:1rem;max-width:960px;padding:0px 1.0875rem 1.45rem;padding-top:0;" data-reactid="27"><div class="blog-post-container" data-reactid="28"><!-- react-empty: 29 --><div class="blog-post" data-reactid="30"><div style="width:135px;margin-bottom:1rem;margin-left:auto;margin-right:auto;" data-reactid="31"><div style="background-color:rgb(0, 209, 193);border-radius:50px;width:130px;color:white;height:30px;margin-bottom:1rem;" data-reactid="32"><p style="font-family:&#39;Roboto&#39;, sans-serif;letter-spacing:.125rem;font-size:.85rem;font-weight:500;line-height:1.85rem;padding:0px;margin:0px;text-align:center;" data-reactid="33">COMMUNITY</p></div></div><h1 style="margin-top:0px;margin-bottom:0.5rem;text-align:center;margin-left:auto;margin-right:auto;max-width:861px;" data-reactid="34">Turning Design Mockups Into Code With Deep Learning</h1><h4 style="margin-top:0px;color:hsla(0, 0%, 0%, .3);text-align:center;margin-bottom:1.5rem;" data-reactid="35"><!-- react-text: 36 -->Emil Wallner<!-- /react-text --><!-- react-text: 37 --> on<!-- /react-text --><!-- react-text: 38 --> <!-- /react-text --><!-- react-text: 39 -->January 9, 2018<!-- /react-text --></h4><hr style="margin-left:auto;margin-right:auto;max-width:768px;background:none;border-top:1px solid rgb(234, 236, 238);height:0px;" data-reactid="40"><div class="blog-post-content" style="margin-left:auto;margin-right:auto;max-width:768px;" data-reactid="41"><p>Within three years deep learning will change front-end development. It will increase prototyping speed and lower the barrier for building software.</p>
<p>The field took off last year when Tony Beltramelli introduced the <a href="https://arxiv.org/abs/1705.07962">pix2code paper</a> and Airbnb launched <a href="https://airbnb.design/sketching-interfaces/">sketch2code</a>. </p>
<p>Currently, the largest barrier to automating front-end development is computing power. However, we can use current deep learning algorithms, along with synthesized training data, to start exploring artificial front-end automation right now.</p>
<p>In this post, we’ll teach a neural network how to code a basic a HTML and CSS website based on a picture of a design mockup. Here's a quick overview of the process: </p>
<h3>1) Give a design image to the trained neural network</h3>

  <a class="gatsby-resp-image-link" href="https://blog.floydhub.com/static/image_to_notebookfile-3354b407064e4d95a0217612a5463434-4a3e0.png" style="display: block" target="_blank" rel="noopener">
  
  <span class="gatsby-resp-image-wrapper" style="position: relative; display: block; ; max-width: 768px; margin-left: auto; margin-right: auto;">
    <span class="gatsby-resp-image-background-image" style="padding-bottom: 43.43240651965484%; position: relative; bottom: 0; left: 0; background-image: url(&#39;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAJCAYAAAAywQxIAAAACXBIWXMAAAsSAAALEgHS3X78AAABs0lEQVQoz42Su2oqURSG7W2sBB/CJ7DxBQTxBaysxQfQBxA7KwsvhQkiyFFPJ3hBa/HkMJ5YGiGZOM6MM3ucq+KfvXYuJIED2fCzYNba3/w/a4fwgxMEAebzOYrFIkqlEiaTyUfver1+mQ3R8Pl8hmEYOB6PUFUVh8MBuq6DMYbNZoNqtSpAlUoF6XQa4XAYyWQSvV4Ps9nsK5AuEbDRaKBcLiOXyyGTySCVSiGbzWKxWCDg/ZNl4XSyoOkq2u02IpEIotEout0uDJNB1VRhSAA9z4OiKNjtHpDP55FIJBCPx1EoFIRD3/c57ITL5QLXc9G+vUEsFhPAZrMJn//QdV0x8wHcbrcweWyKMJ1OMRwOsVqtRGzHdmAwA7Znc4c6pH8S1vdr3N39wVr6i+fnJyiaImYEkOhk17IYNE2DxV4rRXx3x3jP9T2YvO4ed5D3soBQVJOZok8SQLq0XC7R6XTQarVQq9VQr9cxHo+x3+/hOI6A+nyBwVu8z6KEVIkVoo2SRqMRfvOYw8EAg34fA177/V+QJElsnl4BSZbl/4peRojc2bYtHFD9LvpODukl/OS8AOCpeFTCfjScAAAAAElFTkSuQmCC&#39;); background-size: cover; display: block;">
      <img class="gatsby-resp-image-image" style="width: 100%; height: 100%; margin: 0; vertical-align: middle; position: absolute; top: 0; left: 0; box-shadow: inset 0px 0px 0px 400px white;" alt="image to notebookfile" title="" src="./Turning Design Mockups Into Code With Deep Learning - FloydHub Blog_files/image_to_notebookfile-3354b407064e4d95a0217612a5463434-6c1a3.png" srcset="/static/image_to_notebookfile-3354b407064e4d95a0217612a5463434-4f362.png 192w,
/static/image_to_notebookfile-3354b407064e4d95a0217612a5463434-1883a.png 384w,
/static/image_to_notebookfile-3354b407064e4d95a0217612a5463434-6c1a3.png 768w,
/static/image_to_notebookfile-3354b407064e4d95a0217612a5463434-4a3e0.png 1043w" sizes="(max-width: 768px) 100vw, 768px">
    </span>
  </span>
  
  </a>
    
<h3>2) The neural network converts the image into HTML markup</h3>
<img src="./Turning Design Mockups Into Code With Deep Learning - FloydHub Blog_files/generate_html_markup-b6ceec69a7c9cfd447d188648049f2a4.gif" style="width: 768px;">
<h3>3) Rendered output</h3>

  <a class="gatsby-resp-image-link" href="https://blog.floydhub.com/static/render_example-4c9df7e5e8bb455c71dd7856acca7aae-843a4.png" style="display: block" target="_blank" rel="noopener">
  
  <span class="gatsby-resp-image-wrapper" style="position: relative; display: block; ; max-width: 768px; margin-left: auto; margin-right: auto;">
    <span class="gatsby-resp-image-background-image" style="padding-bottom: 64.2016806722689%; position: relative; bottom: 0; left: 0; background-image: url(&#39;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAANCAYAAACpUE5eAAAACXBIWXMAAAsSAAALEgHS3X78AAABkElEQVQ4y6VTO4vCQBj0P4mNhT/C118QK0EsrCR3URO0EEEUfDS2tlba2JyFInieUYsjpFDwERIQ8lDQud098MGdh+EWZmd2w0z2+zZxnc9nWJaF/X7P2DRNxrZtOwL10CwXnZrNJvh0Glz6FRzHIZvNIp/PQRRFBkEQCAvfzLQInueJJ4MX4ssQ9Hq9a2C73Uaj0bigVquhWq2iXC6zF0SjUUQikTsUi8U7z2g0ugYeDgfcjs1mg+l0ivl8jlwuB7fb/QPj8fjOQ8t+GLjdbjGZTCBJEik9zwK8Xi98Ph88Ho/zQMMwoKoqdE1Fv//GWkDLqtfrF71er58P7Ha7GA6H7OY7nc6v+nQ6OTuhpmnQdf2hpr6nA3e7HeufIn9CIpejKAqkj3fMZhJkWWbaIt+ro5ITiQRKpRLi8TgqlQpisRiSySQKhQLbWy6XzwfSNT3BwTbZn3MkTMs9WgZb26ZBzH/0MJVKwe/3XxAMBhEKhRiovn0WCAQQDocZ3+63Wq1r4GKxwGAw+BdWqxUL/AKdWm3ajjWTpAAAAABJRU5ErkJggg==&#39;); background-size: cover; display: block;">
      <img class="gatsby-resp-image-image" style="width: 100%; height: 100%; margin: 0; vertical-align: middle; position: absolute; top: 0; left: 0; box-shadow: inset 0px 0px 0px 400px white;" alt="render example" title="" src="./Turning Design Mockups Into Code With Deep Learning - FloydHub Blog_files/render_example-4c9df7e5e8bb455c71dd7856acca7aae-6c1a3.png" srcset="/static/render_example-4c9df7e5e8bb455c71dd7856acca7aae-4f362.png 192w,
/static/render_example-4c9df7e5e8bb455c71dd7856acca7aae-1883a.png 384w,
/static/render_example-4c9df7e5e8bb455c71dd7856acca7aae-6c1a3.png 768w,
/static/render_example-4c9df7e5e8bb455c71dd7856acca7aae-650d4.png 1152w,
/static/render_example-4c9df7e5e8bb455c71dd7856acca7aae-bbf5a.png 1536w,
/static/render_example-4c9df7e5e8bb455c71dd7856acca7aae-c6553.png 2304w,
/static/render_example-4c9df7e5e8bb455c71dd7856acca7aae-843a4.png 3570w" sizes="(max-width: 768px) 100vw, 768px">
    </span>
  </span>
  
  </a>
    
<p>We’ll build the neural network in three iterations. </p>
<p>In the first version, we’ll make a bare minimum version to get a hang of the moving parts. The second version, HTML, will focus on automating all the steps and explaining the neural network layers. In the final version, Bootstrap, we’ll create a model that can generalize and explore the LSTM layer. </p>
<p>All the code is prepared on <a href="https://github.com/emilwallner/Screenshot-to-code-in-Keras/blob/master/README.md">Github</a> and <a href="https://www.floydhub.com/emilwallner/projects/picturetocode">FloydHub</a> in Jupyter notebooks. All the FloydHub notebooks are inside the <code>floydhub</code> directory and the local equivalents are under <code>local</code>.</p>
<p>The models are based on Beltramelli‘s <a href="https://arxiv.org/abs/1705.07962">pix2code paper</a> and Jason Brownlee’s <a href="https://machinelearningmastery.com/blog/page/2/">image caption tutorials</a>. The code is written in Python and Keras, a framework on top of TensorFlow. </p>
<p>If you’re new to deep learning, I’d recommend getting a feel for Python, backpropagation, and convolutional neural networks. My three earlier posts on FloydHub’s blog will get you started <a href="https://blog.floydhub.com/my-first-weekend-of-deep-learning/">[1]</a> <a href="https://blog.floydhub.com/coding-the-history-of-deep-learning/">[2]</a> <a href="https://blog.floydhub.com/colorizing-b&amp;w-photos-with-neural-networks/">[3]</a>.</p>
<h1>Core Logic</h1>
<p>Let’s recap our goal. We want to build a neural network that will generate HTML/CSS markup that corresponds to a screenshot.</p>
<p>When you train the neural network, you give it several screenshots with matching HTML. </p>
<p>It learns by predicting all the matching HTML markup tags one by one. When it predicts the next markup tag, it receives the screenshot as well as all the correct markup tags until that point. </p>
<p>Here is a simple <a href="https://docs.google.com/spreadsheets/d/1xXwarcQZAHluorveZsACtXRdmNFbwGtN3WMNhcTdEyQ/edit?usp=sharing">training data example</a> in a Google Sheet.</p>
<p>Creating a model that predicts word by word is the most common approach today. There are <a href="https://machinelearningmastery.com/deep-learning-caption-generation-models/">other approaches</a>, but that’s the method that we’ll use throughout this tutorial. </p>
<p>Notice that for each prediction it gets the same screenshot. So if it has to predict 20 words, it will get the same design mockup twenty times. For now, don’t worry about how the neural network works. Focus on grasping the input and output of the neural network.</p>

  <a class="gatsby-resp-image-link" href="https://blog.floydhub.com/static/neural_network_overview-82bea09299f242ad5d6e1236b9661ec6-ecc59.png" style="display: block" target="_blank" rel="noopener">
  
  <span class="gatsby-resp-image-wrapper" style="position: relative; display: block; ; max-width: 768px; margin-left: auto; margin-right: auto;">
    <span class="gatsby-resp-image-background-image" style="padding-bottom: 25.146962769431745%; position: relative; bottom: 0; left: 0; background-image: url(&#39;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAFCAYAAABFA8wzAAAACXBIWXMAAAsSAAALEgHS3X78AAAAl0lEQVQY05WQsQrCMBiE+3ROgjiID+AiKKLv4MsJDra0VayDpoUsCdFiGiQkp/1FnDLk4IO7/+CGP0FA1loopSCEgDEGWmtIKYneh5SEimvzQnp84FDeUVRPlJeOcnZqkZ/b+MHVlmMwu2G8ZJisa0w3NYZzRrfRgsUPFpXBLtNfUv33H/Z5Fz/onIP3nuCc0+9+ue9CegMYknu3fTZF+AAAAABJRU5ErkJggg==&#39;); background-size: cover; display: block;">
      <img class="gatsby-resp-image-image" style="width: 100%; height: 100%; margin: 0; vertical-align: middle; position: absolute; top: 0; left: 0; box-shadow: inset 0px 0px 0px 400px white;" alt="neural network overview" title="" src="./Turning Design Mockups Into Code With Deep Learning - FloydHub Blog_files/neural_network_overview-82bea09299f242ad5d6e1236b9661ec6-6c1a3.png" srcset="/static/neural_network_overview-82bea09299f242ad5d6e1236b9661ec6-4f362.png 192w,
/static/neural_network_overview-82bea09299f242ad5d6e1236b9661ec6-1883a.png 384w,
/static/neural_network_overview-82bea09299f242ad5d6e1236b9661ec6-6c1a3.png 768w,
/static/neural_network_overview-82bea09299f242ad5d6e1236b9661ec6-650d4.png 1152w,
/static/neural_network_overview-82bea09299f242ad5d6e1236b9661ec6-ecc59.png 1531w" sizes="(max-width: 768px) 100vw, 768px">
    </span>
  </span>
  
  </a>
    
<br>
<p>Let’s focus on the previous markup. Say we train the network to predict the sentence “I can code”. When it receives “I”, then it predicts “can”. Next time it will receive “I can” and predict “code”. It receives all the previous words and only has to predict the next word. </p>

  <a class="gatsby-resp-image-link" href="https://blog.floydhub.com/static/input_and_output_data-555f7b04c75a202041f0a4438af5cd51-ecc59.png" style="display: block" target="_blank" rel="noopener">
  
  <span class="gatsby-resp-image-wrapper" style="position: relative; display: block; ; max-width: 768px; margin-left: auto; margin-right: auto;">
    <span class="gatsby-resp-image-background-image" style="padding-bottom: 30.241672109732203%; position: relative; bottom: 0; left: 0; background-image: url(&#39;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAGCAYAAADDl76dAAAACXBIWXMAAAsSAAALEgHS3X78AAAAk0lEQVQY052Q6wrDIAyF+/5P6a8iQyai1lv0bAkohbJ1LHDwGM0X44YfY4xxUe9dxH7GdgdJKaG1JoVEhBjjAnJ++guQD1khBBhjBFBrhVIKpRTZW2uRcxbPdzn/EfgwEcYWPF0T2dPqfIOPhHAQjkTIhZu9ocRjf3khd/beQ2u9/mffdxmVi5xzy8+JzrDbP/wnXqdW2XdZ58p7AAAAAElFTkSuQmCC&#39;); background-size: cover; display: block;">
      <img class="gatsby-resp-image-image" style="width: 100%; height: 100%; margin: 0; vertical-align: middle; position: absolute; top: 0; left: 0; box-shadow: inset 0px 0px 0px 400px white;" alt="input and output data" title="" src="./Turning Design Mockups Into Code With Deep Learning - FloydHub Blog_files/input_and_output_data-555f7b04c75a202041f0a4438af5cd51-6c1a3.png" srcset="/static/input_and_output_data-555f7b04c75a202041f0a4438af5cd51-4f362.png 192w,
/static/input_and_output_data-555f7b04c75a202041f0a4438af5cd51-1883a.png 384w,
/static/input_and_output_data-555f7b04c75a202041f0a4438af5cd51-6c1a3.png 768w,
/static/input_and_output_data-555f7b04c75a202041f0a4438af5cd51-650d4.png 1152w,
/static/input_and_output_data-555f7b04c75a202041f0a4438af5cd51-ecc59.png 1531w" sizes="(max-width: 768px) 100vw, 768px">
    </span>
  </span>
  
  </a>
    
<p>From the data the neural network creates features. The neural network builds features to link the input data with the output data. It has to create representations to understand what is in each screenshot, the HTML syntax, that it has predicted. This builds the knowledge to predict the next tag.</p>
<p>When you want to use the trained model for real-world usage, it's similar to when you train the model. The text is generated one by one with the same screenshot each time. Instead of feeding it with the correct HTML tags, it receives the markup it has generated so far. Then it predicts the next markup tag.
The prediction is initiated with a "start tag" and stops when it predicts an “end tag” or reaches a max limit. Here's another example in <a href="https://docs.google.com/spreadsheets/d/1yneocsAb_w3-ZUdhwJ1odfsxR2kr-4e_c5FabQbNJrs/edit?usp=sharing">a Google Sheet</a>. </p>

  <a class="gatsby-resp-image-link" href="https://blog.floydhub.com/static/model_prediction-801ad7af1d2205276ba64fdc6d7c7ec8-ecc59.png" style="display: block" target="_blank" rel="noopener">
  
  <span class="gatsby-resp-image-wrapper" style="position: relative; display: block; ; max-width: 768px; margin-left: auto; margin-right: auto;">
    <span class="gatsby-resp-image-background-image" style="padding-bottom: 25.146962769431745%; position: relative; bottom: 0; left: 0; background-image: url(&#39;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAFCAYAAABFA8wzAAAACXBIWXMAAAsSAAALEgHS3X78AAAAtElEQVQY041Q2wqCQBD163oKoofoA3oJiqh/6OeCHlLUInsoDVZBsdzWpRU9NRsWFGIDh52ZPXPmYqDBiqJAmqaI4xhSSgghkCSJRu3T+21Gk+DxfIe5vWLjXuB4N7iHXMfWLoO9z1CWpW4URRGqqmoXnC0ZOqMT+lMfg3mA4SJAd+zrXG/iv3kkTJu0CjqexMoSL5ji4z+xtnPNUUohDMP/JqTORCQwxvTN6pj+6H6c85+6B/gCejEeFZ4TAAAAAElFTkSuQmCC&#39;); background-size: cover; display: block;">
      <img class="gatsby-resp-image-image" style="width: 100%; height: 100%; margin: 0; vertical-align: middle; position: absolute; top: 0; left: 0; box-shadow: inset 0px 0px 0px 400px white;" alt="model prediction" title="" src="./Turning Design Mockups Into Code With Deep Learning - FloydHub Blog_files/model_prediction-801ad7af1d2205276ba64fdc6d7c7ec8-6c1a3.png" srcset="/static/model_prediction-801ad7af1d2205276ba64fdc6d7c7ec8-4f362.png 192w,
/static/model_prediction-801ad7af1d2205276ba64fdc6d7c7ec8-1883a.png 384w,
/static/model_prediction-801ad7af1d2205276ba64fdc6d7c7ec8-6c1a3.png 768w,
/static/model_prediction-801ad7af1d2205276ba64fdc6d7c7ec8-650d4.png 1152w,
/static/model_prediction-801ad7af1d2205276ba64fdc6d7c7ec8-ecc59.png 1531w" sizes="(max-width: 768px) 100vw, 768px">
    </span>
  </span>
  
  </a>
    
<h1><strong>Hello World Version</strong></h1>
<p>Let’s build a hello world version. We’ll feed a neural network a screenshot with a website displaying “Hello World!”, and teach it to generate the markup. </p>
<img src="./Turning Design Mockups Into Code With Deep Learning - FloydHub Blog_files/hello_world_generation-039d78c27eb584fa639b89d564b94772.gif" style="width: 768px;">
<p>First, the neural network maps the design mockup into a list of pixel values. From 0 - 255 in three channels - red, blue, and green.</p>

  <a class="gatsby-resp-image-link" href="https://blog.floydhub.com/static/website_pixels-6f11057880ea91a87ddc087c27d063a7-ef96e.png" style="display: block" target="_blank" rel="noopener">
  
  <span class="gatsby-resp-image-wrapper" style="position: relative; display: block; ; max-width: 768px; margin-left: auto; margin-right: auto;">
    <span class="gatsby-resp-image-background-image" style="padding-bottom: 36.71875%; position: relative; bottom: 0; left: 0; background-image: url(&#39;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAHCAYAAAAIy204AAAACXBIWXMAAAsSAAALEgHS3X78AAAA7ElEQVQoz5WRO2vCUBiG/UHOdXPs6lY6CS5uhRa69Qd0rDi5OJV2DJ26tEOnLqUtLTh5QVFJk5Bwcjm5EJJHTxApqKgvvMP5Lg/f950SK+V5ThzHa0dRtGFVs0+l/0DP85BS4vs+juNgWRYyDPFlSLCMK2gQBPz0hmivfbSXPu/f891A1bBN4RIqhMAwDJzpjN+LSz6ur3i+vaH19Hk40DTNApQkSfFWeTEaQ6UG1TMG9SZ3xwBd1y2Ayuoca2D5FE5qDM8bPLx9Hb+yUpZlxcrGeIJodxGde/4eNeLV9FuBtm2j6/pOp2m695cX+UERjzt8TYAAAAAASUVORK5CYII=&#39;); background-size: cover; display: block;">
      <img class="gatsby-resp-image-image" style="width: 100%; height: 100%; margin: 0; vertical-align: middle; position: absolute; top: 0; left: 0; box-shadow: inset 0px 0px 0px 400px white;" alt="website pixels" title="" src="./Turning Design Mockups Into Code With Deep Learning - FloydHub Blog_files/website_pixels-6f11057880ea91a87ddc087c27d063a7-6c1a3.png" srcset="/static/website_pixels-6f11057880ea91a87ddc087c27d063a7-4f362.png 192w,
/static/website_pixels-6f11057880ea91a87ddc087c27d063a7-1883a.png 384w,
/static/website_pixels-6f11057880ea91a87ddc087c27d063a7-6c1a3.png 768w,
/static/website_pixels-6f11057880ea91a87ddc087c27d063a7-650d4.png 1152w,
/static/website_pixels-6f11057880ea91a87ddc087c27d063a7-bbf5a.png 1536w,
/static/website_pixels-6f11057880ea91a87ddc087c27d063a7-c6553.png 2304w,
/static/website_pixels-6f11057880ea91a87ddc087c27d063a7-ef96e.png 3840w" sizes="(max-width: 768px) 100vw, 768px">
    </span>
  </span>
  
  </a>
    
<p>To represent the markup in a way that the neural network understands, I use <a href="https://machinelearningmastery.com/how-to-one-hot-encode-sequence-data-in-python/">one hot encoding</a>. Thus, the sentence “I can code”, could be mapped like the below.</p>

  <a class="gatsby-resp-image-link" href="https://blog.floydhub.com/static/one_hot_encoding-2a72d2b794b26e6e4c4cc9c5f8bd4649-ef96e.png" style="display: block" target="_blank" rel="noopener">
  
  <span class="gatsby-resp-image-wrapper" style="position: relative; display: block; ; max-width: 768px; margin-left: auto; margin-right: auto;">
    <span class="gatsby-resp-image-background-image" style="padding-bottom: 31.041666666666668%; position: relative; bottom: 0; left: 0; background-image: url(&#39;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAGCAYAAADDl76dAAAACXBIWXMAAAsSAAALEgHS3X78AAAAhElEQVQY06WP3QqFIBCEe/9H9C9T0kJS0TtN5pBQd3LonIFhWXb5mJnwRaUUpJTQWkPOGcdxIMY4/J9GB+dct/ce1loYY7Cu6+PXwPM8OyiEgG3b/gfeda+UWmsopSCl7F6W5T2w1gpCSE/JGAPnvE9KafdPlS/Ivu+Y5xlCiAd87SN9ABi90cobAx5EAAAAAElFTkSuQmCC&#39;); background-size: cover; display: block;">
      <img class="gatsby-resp-image-image" style="width: 100%; height: 100%; margin: 0; vertical-align: middle; position: absolute; top: 0; left: 0; box-shadow: inset 0px 0px 0px 400px white;" alt="one hot encoding" title="" src="./Turning Design Mockups Into Code With Deep Learning - FloydHub Blog_files/one_hot_encoding-2a72d2b794b26e6e4c4cc9c5f8bd4649-6c1a3.png" srcset="/static/one_hot_encoding-2a72d2b794b26e6e4c4cc9c5f8bd4649-4f362.png 192w,
/static/one_hot_encoding-2a72d2b794b26e6e4c4cc9c5f8bd4649-1883a.png 384w,
/static/one_hot_encoding-2a72d2b794b26e6e4c4cc9c5f8bd4649-6c1a3.png 768w,
/static/one_hot_encoding-2a72d2b794b26e6e4c4cc9c5f8bd4649-650d4.png 1152w,
/static/one_hot_encoding-2a72d2b794b26e6e4c4cc9c5f8bd4649-bbf5a.png 1536w,
/static/one_hot_encoding-2a72d2b794b26e6e4c4cc9c5f8bd4649-c6553.png 2304w,
/static/one_hot_encoding-2a72d2b794b26e6e4c4cc9c5f8bd4649-ef96e.png 3840w" sizes="(max-width: 768px) 100vw, 768px">
    </span>
  </span>
  
  </a>
    
<br>
<p>In the above graphic, we include the start and end tag. These tags are cues for when the network starts its predictions and when to stop.  </p>
<p>For the input data, we will use sentences, starting with the first word and then adding each word one by one. The output data is always one word. </p>
<p>Sentences follow the same logic as words. They also need the same input length. Instead of being capped by the vocabulary they are bound by maximum sentence length. If it’s shorter than the maximum length, you fill it up with empty words, a word with just zeros. </p>

  <a class="gatsby-resp-image-link" href="https://blog.floydhub.com/static/one_hot_sentence-6b3c930c8a7808b928639201cac78ebe-ef96e.png" style="display: block" target="_blank" rel="noopener">
  
  <span class="gatsby-resp-image-wrapper" style="position: relative; display: block; ; max-width: 768px; margin-left: auto; margin-right: auto;">
    <span class="gatsby-resp-image-background-image" style="padding-bottom: 31.041666666666668%; position: relative; bottom: 0; left: 0; background-image: url(&#39;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAGCAYAAADDl76dAAAACXBIWXMAAAsSAAALEgHS3X78AAAA30lEQVQY032QSYqEQBBF69jOXkGlHE/gcADRC4hbl25cqQgiKqgo4i8ywIZqug1IXkZCvPyZLzzUsizY9x3nef70bD/PM47jwDiOuK7ra+b1WzJNE/q+R9u2sCwLURQRwzCEbdsIggCO48D3fXiehyzLnoWstm1DXdc0yISMTOi6LglvsvM8z5+F7AnDMJCQ53kYhkHUdR2CIEDTNOpvJknyv3BdVzRNg7IsURQFZFmGaZrE9/tNZBcoikJUVRVpmv4tZJ/cdR0tlq6qKnAcR4M376SiKFJCSZIQx/GX8AO+bJrF4q9wnAAAAABJRU5ErkJggg==&#39;); background-size: cover; display: block;">
      <img class="gatsby-resp-image-image" style="width: 100%; height: 100%; margin: 0; vertical-align: middle; position: absolute; top: 0; left: 0; box-shadow: inset 0px 0px 0px 400px white;" alt="one hot sentence" title="" src="./Turning Design Mockups Into Code With Deep Learning - FloydHub Blog_files/one_hot_sentence-6b3c930c8a7808b928639201cac78ebe-6c1a3.png" srcset="/static/one_hot_sentence-6b3c930c8a7808b928639201cac78ebe-4f362.png 192w,
/static/one_hot_sentence-6b3c930c8a7808b928639201cac78ebe-1883a.png 384w,
/static/one_hot_sentence-6b3c930c8a7808b928639201cac78ebe-6c1a3.png 768w,
/static/one_hot_sentence-6b3c930c8a7808b928639201cac78ebe-650d4.png 1152w,
/static/one_hot_sentence-6b3c930c8a7808b928639201cac78ebe-bbf5a.png 1536w,
/static/one_hot_sentence-6b3c930c8a7808b928639201cac78ebe-c6553.png 2304w,
/static/one_hot_sentence-6b3c930c8a7808b928639201cac78ebe-ef96e.png 3840w" sizes="(max-width: 768px) 100vw, 768px">
    </span>
  </span>
  
  </a>
    
<br>
<p>As you see, words are printed from right to left. This forces each word to change position for each training round. This allows the model to learn the sequence instead of memorizing the position of each word. </p>
<p>In the below graphic there are four predictions. Each row is one prediction. To the left are the images represented in their three color channels: red, green and blue and the previous words. Outside of the brackets, are the predictions one by one, ending with a red square to mark the end. </p>

  <a class="gatsby-resp-image-link" href="https://blog.floydhub.com/static/model_function-068c180c2ba3efdbb54193f21a5d5d7d-ef96e.png" style="display: block" target="_blank" rel="noopener">
  
  <span class="gatsby-resp-image-wrapper" style="position: relative; display: block; ; max-width: 768px; margin-left: auto; margin-right: auto;">
    <span class="gatsby-resp-image-background-image" style="padding-bottom: 16.09375%; position: relative; bottom: 0; left: 0; background-image: url(&#39;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAADCAYAAACTWi8uAAAACXBIWXMAAAsSAAALEgHS3X78AAAAoUlEQVQI122OOwvCMBRG++vFxdHFxd1V7NDJQZcOhqISFStNbEv6oA8EMdORBgQFz3SHw7mfxxdt22LDA8vbHWXAf0Qce0XTNFRVRdd19H3vvAFrLWVZfifwPkeWZSileC4CRuGe3QXG9YqgECRJgpSSPM8pigJjDHEcO18I8T84MKx4+Rum0QlxtsyaNdtaumdDME1TtNbOcwuvGjOZ/wTfWGXe5xGEOXoAAAAASUVORK5CYII=&#39;); background-size: cover; display: block;">
      <img class="gatsby-resp-image-image" style="width: 100%; height: 100%; margin: 0; vertical-align: middle; position: absolute; top: 0; left: 0; box-shadow: inset 0px 0px 0px 400px white;" alt="model function" title="" src="./Turning Design Mockups Into Code With Deep Learning - FloydHub Blog_files/model_function-068c180c2ba3efdbb54193f21a5d5d7d-6c1a3.png" srcset="/static/model_function-068c180c2ba3efdbb54193f21a5d5d7d-4f362.png 192w,
/static/model_function-068c180c2ba3efdbb54193f21a5d5d7d-1883a.png 384w,
/static/model_function-068c180c2ba3efdbb54193f21a5d5d7d-6c1a3.png 768w,
/static/model_function-068c180c2ba3efdbb54193f21a5d5d7d-650d4.png 1152w,
/static/model_function-068c180c2ba3efdbb54193f21a5d5d7d-bbf5a.png 1536w,
/static/model_function-068c180c2ba3efdbb54193f21a5d5d7d-c6553.png 2304w,
/static/model_function-068c180c2ba3efdbb54193f21a5d5d7d-ef96e.png 3840w" sizes="(max-width: 768px) 100vw, 768px">
    </span>
  </span>
  
  </a>
    
<br>
<div class="gatsby-highlight">
      <pre class="language-python"><code>    <span class="token comment" spellcheck="true">#Length of longest sentence</span>
    max_caption_len <span class="token operator">=</span> <span class="token number">3</span>
    <span class="token comment" spellcheck="true">#Size of vocabulary </span>
    vocab_size <span class="token operator">=</span> <span class="token number">3</span>
    
    <span class="token comment" spellcheck="true"># Load one screenshot for each word and turn them into digits </span>
    images <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
    <span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        images<span class="token punctuation">.</span>append<span class="token punctuation">(</span>img_to_array<span class="token punctuation">(</span>load_img<span class="token punctuation">(</span><span class="token string">'screenshot.jpg'</span><span class="token punctuation">,</span> target_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">224</span><span class="token punctuation">,</span> <span class="token number">224</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    images <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>images<span class="token punctuation">,</span> dtype<span class="token operator">=</span>float<span class="token punctuation">)</span>
    <span class="token comment" spellcheck="true"># Preprocess input for the VGG16 model</span>
    images <span class="token operator">=</span> preprocess_input<span class="token punctuation">(</span>images<span class="token punctuation">)</span>
    
    <span class="token comment" spellcheck="true">#Turn start tokens into one-hot encoding</span>
    html_input <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>
                <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token comment" spellcheck="true">#start</span>
                 <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                 <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                 <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token comment" spellcheck="true">#start &lt;HTML&gt;Hello World!&lt;/HTML&gt;</span>
                 <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                 <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    
    <span class="token comment" spellcheck="true">#Turn next word into one-hot encoding</span>
    next_words <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>
                <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token comment" spellcheck="true"># &lt;HTML&gt;Hello World!&lt;/HTML&gt;</span>
                 <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># end</span>
    
    <span class="token comment" spellcheck="true"># Load the VGG16 model trained on imagenet and output the classification feature</span>
    VGG <span class="token operator">=</span> VGG16<span class="token punctuation">(</span>weights<span class="token operator">=</span><span class="token string">'imagenet'</span><span class="token punctuation">,</span> include_top<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
    <span class="token comment" spellcheck="true"># Extract the features from the image</span>
    features <span class="token operator">=</span> VGG<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>images<span class="token punctuation">)</span>
    
    <span class="token comment" spellcheck="true">#Load the feature to the network, apply a dense layer, and repeat the vector</span>
    vgg_feature <span class="token operator">=</span> Input<span class="token punctuation">(</span>shape<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1000</span><span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    vgg_feature_dense <span class="token operator">=</span> Dense<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">(</span>vgg_feature<span class="token punctuation">)</span>
    vgg_feature_repeat <span class="token operator">=</span> RepeatVector<span class="token punctuation">(</span>max_caption_len<span class="token punctuation">)</span><span class="token punctuation">(</span>vgg_feature_dense<span class="token punctuation">)</span>
    <span class="token comment" spellcheck="true"># Extract information from the input seqence </span>
    language_input <span class="token operator">=</span> Input<span class="token punctuation">(</span>shape<span class="token operator">=</span><span class="token punctuation">(</span>vocab_size<span class="token punctuation">,</span> vocab_size<span class="token punctuation">)</span><span class="token punctuation">)</span>
    language_model <span class="token operator">=</span> LSTM<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">,</span> return_sequences<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">(</span>language_input<span class="token punctuation">)</span>
    
    <span class="token comment" spellcheck="true"># Concatenate the information from the image and the input</span>
    decoder <span class="token operator">=</span> concatenate<span class="token punctuation">(</span><span class="token punctuation">[</span>vgg_feature_repeat<span class="token punctuation">,</span> language_model<span class="token punctuation">]</span><span class="token punctuation">)</span>
    <span class="token comment" spellcheck="true"># Extract information from the concatenated output</span>
    decoder <span class="token operator">=</span> LSTM<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">,</span> return_sequences<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">(</span>decoder<span class="token punctuation">)</span>
    <span class="token comment" spellcheck="true"># Predict which word comes next</span>
    decoder_output <span class="token operator">=</span> Dense<span class="token punctuation">(</span>vocab_size<span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">'softmax'</span><span class="token punctuation">)</span><span class="token punctuation">(</span>decoder<span class="token punctuation">)</span>
    <span class="token comment" spellcheck="true"># Compile and run the neural network</span>
    model <span class="token operator">=</span> Model<span class="token punctuation">(</span>inputs<span class="token operator">=</span><span class="token punctuation">[</span>vgg_feature<span class="token punctuation">,</span> language_input<span class="token punctuation">]</span><span class="token punctuation">,</span> outputs<span class="token operator">=</span>decoder_output<span class="token punctuation">)</span>
    model<span class="token punctuation">.</span>compile<span class="token punctuation">(</span>loss<span class="token operator">=</span><span class="token string">'categorical_crossentropy'</span><span class="token punctuation">,</span> optimizer<span class="token operator">=</span><span class="token string">'rmsprop'</span><span class="token punctuation">)</span>
    
    <span class="token comment" spellcheck="true"># Train the neural network</span>
    model<span class="token punctuation">.</span>fit<span class="token punctuation">(</span><span class="token punctuation">[</span>features<span class="token punctuation">,</span> html_input<span class="token punctuation">]</span><span class="token punctuation">,</span> next_words<span class="token punctuation">,</span> batch_size<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> epochs<span class="token operator">=</span><span class="token number">1000</span><span class="token punctuation">)</span>
</code></pre>
      </div>
<br>
<p>In the hello world version we use three tokens: “start”, “Hello World!” and “end”. A token can be anything. It can be a character, word or sentence. Character versions require a smaller vocabulary but constrain the neural network. Word level tokens tend to perform best.  </p>
<p>Here we make the prediction:</p>
<div class="gatsby-highlight">
      <pre class="language-python"><code>    <span class="token comment" spellcheck="true"># Create an empty sentence and insert the start token</span>
    sentence <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># [[0,0,0], [0,0,0], [0,0,0]]</span>
    start_token <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">]</span> <span class="token comment" spellcheck="true"># start</span>
    sentence<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span> <span class="token operator">=</span> start_token <span class="token comment" spellcheck="true"># place start in empty sentence</span>
    
    <span class="token comment" spellcheck="true"># Making the first prediction with the start token</span>
    second_word <span class="token operator">=</span> model<span class="token punctuation">.</span>predict<span class="token punctuation">(</span><span class="token punctuation">[</span>np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span>features<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> sentence<span class="token punctuation">]</span><span class="token punctuation">)</span>
    
    <span class="token comment" spellcheck="true"># Put the second word in the sentence and make the final prediction</span>
    sentence<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">=</span> start_token
    sentence<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span> <span class="token operator">=</span> np<span class="token punctuation">.</span>round<span class="token punctuation">(</span>second_word<span class="token punctuation">)</span>
    third_word <span class="token operator">=</span> model<span class="token punctuation">.</span>predict<span class="token punctuation">(</span><span class="token punctuation">[</span>np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span>features<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> sentence<span class="token punctuation">]</span><span class="token punctuation">)</span>
    
    <span class="token comment" spellcheck="true"># Place the start token and our two predictions in the sentence </span>
    sentence<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">=</span> start_token
    sentence<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">=</span> np<span class="token punctuation">.</span>round<span class="token punctuation">(</span>second_word<span class="token punctuation">)</span>
    sentence<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span> <span class="token operator">=</span> np<span class="token punctuation">.</span>round<span class="token punctuation">(</span>third_word<span class="token punctuation">)</span>
    
    <span class="token comment" spellcheck="true"># Transform our one-hot predictions into the final tokens</span>
    vocabulary <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">"start"</span><span class="token punctuation">,</span> <span class="token string">"&lt;HTML&gt;&lt;center&gt;&lt;H1&gt;Hello World!&lt;/H1&gt;&lt;/center&gt;&lt;/HTML&gt;"</span><span class="token punctuation">,</span> <span class="token string">"end"</span><span class="token punctuation">]</span>
    <span class="token keyword">for</span> i <span class="token keyword">in</span> sentence<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">:</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span>vocabulary<span class="token punctuation">[</span>np<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>i<span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">,</span> end<span class="token operator">=</span><span class="token string">' '</span><span class="token punctuation">)</span>
</code></pre>
      </div>
<h2>Output</h2>
<ul>
<li><strong>10 epochs:</strong> <code>start start start</code></li>
<li><strong>100 epochs:</strong> <code>start &lt;HTML&gt;&lt;center&gt;&lt;H1&gt;Hello World!&lt;/H1&gt;&lt;/center&gt;&lt;/HTML&gt; &lt;HTML&gt;&lt;center&gt;&lt;H1&gt;Hello World!&lt;/H1&gt;&lt;/center&gt;&lt;/HTML&gt;</code></li>
<li><strong>300 epochs:</strong> <code>start &lt;HTML&gt;&lt;center&gt;&lt;H1&gt;Hello World!&lt;/H1&gt;&lt;/center&gt;&lt;/HTML&gt; end</code></li>
</ul>
<h3>Mistakes I made:</h3>
<ul>
<li><strong>Build the first working version before gathering the data.</strong> Early on in this project, I managed to get a copy of an old archive of the Geocities hosting website. It had 38 million websites. Blinded by the potential, I ignored the huge workload that would be required to reduce the 100K-sized vocabulary. </li>
<li><strong>Dealing with a terabyte worth of data requires good hardware or a lot of patience.</strong> After having my mac run into several problems I ended up using a powerful remote server. Expect to rent a rig with 8 modern CPU cores and a 1GPS internet connection to have a decent workflow. </li>
<li><strong>Nothing made sense until I understood the input and output data.</strong> The input, X, is one screenshot and the previous markup tags. The output, Y, is the next markup tag. When I got this, it became easier to understand everything between them. It also became easier to experiment with different architectures. </li>
<li><strong>Be aware of the rabbit holes.</strong> Because this project intersects with a lot of fields in deep learning, I got stuck in plenty of rabbit holes along the way. I spent a week programming RNNs from scratch, got too fascinated by embedding vector spaces, and was seduced by exotic implementations. </li>
<li><strong>Picture-to-code networks are image caption models in disguise.</strong> Even when I learned this, I still ignored many of the image caption papers, simply because they were less cool. Once I got some perspective, I accelerated my learning of the problem space. </li>
</ul>
<h2>Running the code on FloydHub</h2>
<p>FloydHub is a training platform for deep learning. I came across them when I first started learning deep learning and I’ve used them since for training and managing my deep learning experiments. You can install it and run your first model within 10 minutes. It’s hands down the best option to run models on cloud GPUs. </p>
<p>If you are new to FloydHub, do their <a href="https://www.floydhub.com/">2-min installation</a> or <a href="https://www.youtube.com/watch?v=byLQ9kgjTdQ&amp;t=21s">my 5-minute walkthrough.</a> </p>
<p>Clone the repository </p>
<div class="gatsby-highlight">
      <pre class="language-bash"><code><span class="token function">git</span> clone https://github.com/emilwallner/Screenshot-to-code-in-Keras.git
</code></pre>
      </div>
<br>
<p>Login and initiate FloydHub command-line-tool</p>
<div class="gatsby-highlight">
      <pre class="language-bash"><code><span class="token function">cd</span> Screenshot-to-code-in-Keras
floyd login
floyd init s2c
</code></pre>
      </div>
<br>
<p>Run a Jupyter notebook on a FloydHub cloud GPU machine:</p>
<div class="gatsby-highlight">
      <pre class="language-bash"><code>floyd run --gpu --env tensorflow-1.4 --data emilwallner/datasets/imagetocode/2:data --mode jupyter
</code></pre>
      </div>
<br>
<p>All the notebooks are prepared inside the floydhub directory. The local equivalents are under local.
Once it’s running, you can find the first notebook here: floydhub/Hello<em>world/hello</em>world.ipynb .</p>
<p>If you want more detailed instructions and an explanation for the flags, check <a href="https://blog.floydhub.com/colorizing-b&amp;w-photos-with-neural-networks/">my earlier post</a>. </p>
<h1>HTML Version</h1>
<p>In this version, we’ll automate many of the steps from the Hello World model. This section will focus on creating a scalable implementation and the moving pieces in the neural network. </p>
<p>This version will not be able to predict HTML from random websites, but it’s still a great setup to explore the dynamics of the problem. </p>
<img src="./Turning Design Mockups Into Code With Deep Learning - FloydHub Blog_files/html_generation-2476413d4299a3a8b407ee9cdb6774b6.gif" style="width: 768px;">
<h3>Overview</h3>
<p>If we expand the components of the previous graphic it looks like this.</p>

  <a class="gatsby-resp-image-link" href="https://blog.floydhub.com/static/model_more_details-68db3bf26f6df205ffe4c541ace33a92-2b038.png" style="display: block" target="_blank" rel="noopener">
  
  <span class="gatsby-resp-image-wrapper" style="position: relative; display: block; ; max-width: 768px; margin-left: auto; margin-right: auto;">
    <span class="gatsby-resp-image-background-image" style="padding-bottom: 34.98014997794442%; position: relative; bottom: 0; left: 0; background-image: url(&#39;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAHCAYAAAAIy204AAAACXBIWXMAAAsSAAALEgHS3X78AAAA9UlEQVQoz5WRTWsCMRCG/a16EA/1IlZKW4qgIH4UeugfKLTQo7T4Z0oPoht3xV2TuJ8mu2/NlF26Fg87MGRmkjzzJlNDBcuyDFJKeJ6HOI7BOSc39dxqVWAHX6MzsnHz6KD/vMX90xa9mQNmy/9AcyFJEvi+D6UUwjBEEARUT9OUVnHQqN9aaPUZ2sMNmg8MjTsLX98OhBBloNYZXuYcb58C7wuB1w9B+V7oors8KbwabNAd/6rsTW3KrUsKXa6x2x+xZpJi40qlhcIcSNCJXcTLtYcoiuhMCXjJ833z5Bxy/Qe4YpyGVGko501d1z19ky41NfYDA7MJT1GXrQMAAAAASUVORK5CYII=&#39;); background-size: cover; display: block;">
      <img class="gatsby-resp-image-image" style="width: 100%; height: 100%; margin: 0; vertical-align: middle; position: absolute; top: 0; left: 0; box-shadow: inset 0px 0px 0px 400px white;" alt="model more details" title="" src="./Turning Design Mockups Into Code With Deep Learning - FloydHub Blog_files/model_more_details-68db3bf26f6df205ffe4c541ace33a92-6c1a3.png" srcset="/static/model_more_details-68db3bf26f6df205ffe4c541ace33a92-4f362.png 192w,
/static/model_more_details-68db3bf26f6df205ffe4c541ace33a92-1883a.png 384w,
/static/model_more_details-68db3bf26f6df205ffe4c541ace33a92-6c1a3.png 768w,
/static/model_more_details-68db3bf26f6df205ffe4c541ace33a92-650d4.png 1152w,
/static/model_more_details-68db3bf26f6df205ffe4c541ace33a92-bbf5a.png 1536w,
/static/model_more_details-68db3bf26f6df205ffe4c541ace33a92-2b038.png 2267w" sizes="(max-width: 768px) 100vw, 768px">
    </span>
  </span>
  
  </a>
    
<br>
<p>There are two major sections. First, the encoder. This is where we create image features and previous markup features. Features are the building blocks that the network creates to connect the design mockups with the markup. At the end of the encoder, we glue the image features to each word in the previous markup. </p>
<p>The decoder then takes the combined design and markup feature and creates a next tag feature. This feature is run through a fully connected neural network to predict the next tag. </p>
<h5>Design mockup features</h5>
<p>Since we need to insert one screenshot for each word, this becomes a bottleneck when training the network (<a href="https://docs.google.com/spreadsheets/d/1xXwarcQZAHluorveZsACtXRdmNFbwGtN3WMNhcTdEyQ/edit#gid=0">example</a>). Instead of using the images, we extract the information we need to generate the markup.  </p>
<p>The information is encoded into image features. This is done by using an already pre-trained convolutional neural network (CNN). The model is pre-trained on Imagenet. </p>
<p>We extract the features from the layer before the final classification.</p>

  <a class="gatsby-resp-image-link" href="https://blog.floydhub.com/static/ir2_to_image_features-5455a0516284ac036482417b56a57d49-d5626.png" style="display: block" target="_blank" rel="noopener">
  
  <span class="gatsby-resp-image-wrapper" style="position: relative; display: block; ; max-width: 768px; margin-left: auto; margin-right: auto;">
    <span class="gatsby-resp-image-background-image" style="padding-bottom: 15.185504745470233%; position: relative; bottom: 0; left: 0; background-image: url(&#39;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAADCAYAAACTWi8uAAAACXBIWXMAAAsSAAALEgHS3X78AAAAWklEQVQI12P4TyZ48+YNVnEGZM7nz5//90zd+b9t5uv/3XPf/J+85O3/SYvf/u+c/RosBsK7j374//z58/8vXrwAG/r9+3fcBhILPn369P/t27f///z5gyEHAMZL5VwJY5U2AAAAAElFTkSuQmCC&#39;); background-size: cover; display: block;">
      <img class="gatsby-resp-image-image" style="width: 100%; height: 100%; margin: 0; vertical-align: middle; position: absolute; top: 0; left: 0; box-shadow: inset 0px 0px 0px 400px white;" alt="ir2 to image features" title="" src="./Turning Design Mockups Into Code With Deep Learning - FloydHub Blog_files/ir2_to_image_features-5455a0516284ac036482417b56a57d49-6c1a3.png" srcset="/static/ir2_to_image_features-5455a0516284ac036482417b56a57d49-4f362.png 192w,
/static/ir2_to_image_features-5455a0516284ac036482417b56a57d49-1883a.png 384w,
/static/ir2_to_image_features-5455a0516284ac036482417b56a57d49-6c1a3.png 768w,
/static/ir2_to_image_features-5455a0516284ac036482417b56a57d49-650d4.png 1152w,
/static/ir2_to_image_features-5455a0516284ac036482417b56a57d49-d5626.png 1159w" sizes="(max-width: 768px) 100vw, 768px">
    </span>
  </span>
  
  </a>
    
<p>We end up with 1536 eight by eight pixel images known as features. Although they are hard to understand for us, a neural network can extract the objects and position of the elements from these features. </p>
<h5>Markup features</h5>
<p>In the hello world version we used a one-hot encoding to represent the markup. In this version, we’ll use a word embedding for the input and keep the one-hot encoding for the output.</p>
<p>The way we structure each sentence stays the same, but how we map each token is changed. One-hot encoding treats each word as an isolated unit. Instead, we convert each word in the input data to lists of digits. These represent the relationship between the markup tags.</p>

  <a class="gatsby-resp-image-link" href="https://blog.floydhub.com/static/embedding-2146c151fd4dbf5dcce6257444931a79-ef96e.png" style="display: block" target="_blank" rel="noopener">
  
  <span class="gatsby-resp-image-wrapper" style="position: relative; display: block; ; max-width: 768px; margin-left: auto; margin-right: auto;">
    <span class="gatsby-resp-image-background-image" style="padding-bottom: 19.322916666666668%; position: relative; bottom: 0; left: 0; background-image: url(&#39;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAECAYAAACOXx+WAAAACXBIWXMAAAsSAAALEgHS3X78AAAAnElEQVQY022OCwuEIBCE+/9/MDRCI3oYRlj2gMrpRrjj7nBgWXfZGb8Mf7quK9Z5nrjvO+6O48A8z1iWBc45TNME7z38a9627cefvR8007iuazzmIXfsbduiLEsIIZDnOaSUcWYZY9KBFKkYRhp2kpKmrmtUVYWiKD5hSilorWGtTQeGEJKE+75jHEcMwxBJm6ZB13Xo+z7S8fNvPaOaM75h8ZO/AAAAAElFTkSuQmCC&#39;); background-size: cover; display: block;">
      <img class="gatsby-resp-image-image" style="width: 100%; height: 100%; margin: 0; vertical-align: middle; position: absolute; top: 0; left: 0; box-shadow: inset 0px 0px 0px 400px white;" alt="embedding" title="" src="./Turning Design Mockups Into Code With Deep Learning - FloydHub Blog_files/embedding-2146c151fd4dbf5dcce6257444931a79-6c1a3.png" srcset="/static/embedding-2146c151fd4dbf5dcce6257444931a79-4f362.png 192w,
/static/embedding-2146c151fd4dbf5dcce6257444931a79-1883a.png 384w,
/static/embedding-2146c151fd4dbf5dcce6257444931a79-6c1a3.png 768w,
/static/embedding-2146c151fd4dbf5dcce6257444931a79-650d4.png 1152w,
/static/embedding-2146c151fd4dbf5dcce6257444931a79-bbf5a.png 1536w,
/static/embedding-2146c151fd4dbf5dcce6257444931a79-c6553.png 2304w,
/static/embedding-2146c151fd4dbf5dcce6257444931a79-ef96e.png 3840w" sizes="(max-width: 768px) 100vw, 768px">
    </span>
  </span>
  
  </a>
    
<br>
<p>The dimension of this word embedding is eight but often vary between 50 - 500 depending on the size of the vocabulary. </p>
<p>The eight digits for each word are weights similar to a vanilla neural network. They are tuned to map how the words relate to each other (<a href="https://arxiv.org/abs/1301.3781">Mikolov alt el., 2013</a>).</p>
<p>This is how we start developing markup features. Features are what the neural network develop to link the input data with the output data. For now, don’t worry about what they are, we’ll dig deeper into this in the next section. </p>
<h3>The Encoder</h3>
<p>We’ll take the word embeddings and run them through an LSTM and return a sequence of markup features. These are run through a Time distributed dense layer - think of it as a dense layer with multiple inputs and outputs. </p>

  <a class="gatsby-resp-image-link" href="https://blog.floydhub.com/static/encoder-78498407f393e83128abed5eec86dd4c-524bf.png" style="display: block" target="_blank" rel="noopener">
  
  <span class="gatsby-resp-image-wrapper" style="position: relative; display: block; ; max-width: 768px; margin-left: auto; margin-right: auto;">
    <span class="gatsby-resp-image-background-image" style="padding-bottom: 29.66047405509289%; position: relative; bottom: 0; left: 0; background-image: url(&#39;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAGCAYAAADDl76dAAAACXBIWXMAAAsSAAALEgHS3X78AAAAuUlEQVQY05WPTwuCQBDF/a4FkRV0K7RILQKhPwR1qk8WQWu17rp6UJBQEF7uCp3cgwMP5s0wP94Y0FRRFOCcg1KKPM+RpimEEGomva4M3eLFStyfXzyCAuRT4l37gDZiokRVVd2A832E/oJi6IQYeQw9u+lNN4R9jJAkSTfg8iTUsYRNt+wPHqxCOGcBQkjr+1qgVaeYbBhMr0k1XjMFlPKvcfeE7qVJONtx9aKUdYjUzL/FyLKs9e4HVnq1lBjbofcAAAAASUVORK5CYII=&#39;); background-size: cover; display: block;">
      <img class="gatsby-resp-image-image" style="width: 100%; height: 100%; margin: 0; vertical-align: middle; position: absolute; top: 0; left: 0; box-shadow: inset 0px 0px 0px 400px white;" alt="encoder" title="" src="./Turning Design Mockups Into Code With Deep Learning - FloydHub Blog_files/encoder-78498407f393e83128abed5eec86dd4c-6c1a3.png" srcset="/static/encoder-78498407f393e83128abed5eec86dd4c-4f362.png 192w,
/static/encoder-78498407f393e83128abed5eec86dd4c-1883a.png 384w,
/static/encoder-78498407f393e83128abed5eec86dd4c-6c1a3.png 768w,
/static/encoder-78498407f393e83128abed5eec86dd4c-650d4.png 1152w,
/static/encoder-78498407f393e83128abed5eec86dd4c-bbf5a.png 1536w,
/static/encoder-78498407f393e83128abed5eec86dd4c-524bf.png 1561w" sizes="(max-width: 768px) 100vw, 768px">
    </span>
  </span>
  
  </a>
    
<br>
<p>In parallel, the image features are first flattened. Regardless of how the digits where structured they are transformed into one large list of numbers. Then we apply a dense layer on this layer to form a high-level features. These image features are then concatenated to the markup features.  </p>
<p>This can be hard to wrap your mind around - so let’s break it down. </p>
<h5>Markup features</h5>
<p>Here we run the word embeddings through the LSTM layer. In this graphic, all the sentences are padded to reach the maximum size of three tokens. </p>

  <a class="gatsby-resp-image-link" href="https://blog.floydhub.com/static/word_embedding_markup_feature-d4e76483527fefd10742c0ddc1cd3227-f669c.png" style="display: block" target="_blank" rel="noopener">
  
  <span class="gatsby-resp-image-wrapper" style="position: relative; display: block; ; max-width: 768px; margin-left: auto; margin-right: auto;">
    <span class="gatsby-resp-image-background-image" style="padding-bottom: 22.79105043610163%; position: relative; bottom: 0; left: 0; background-image: url(&#39;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAFCAYAAABFA8wzAAAACXBIWXMAAAsSAAALEgHS3X78AAAA/0lEQVQY02VPTUsDMRTc3+3RiwiePBQE7U0ED96KC64HBakfsNX2IHhRtCr7kWSTdDfpfo19D5SqgWFC3ryZSYA/J45jRFGEMAwxf3vG7dRicCSxvZ9hZ5jjfKzhnUGe59BaQ0rJUEoxB33fYx0kStMU1lqgb/GeeVw8aJzdaFzFJV7mHvXS8byua3Rd9wtB0zRIkuQnSQjBacRLZ1cmBlsHCTZ2P7E5yHB6WaAqFe8URfG/IRnShYZVVXHyN3u3wOxpgcORwt6xwPBE4frewBrJhsYY/hGB9OQRUG1qQ4/OOYb3nrlta6SiweTRYTwpcTer8PrhV/OS9aSjQuv4Ah1gdRj5oEryAAAAAElFTkSuQmCC&#39;); background-size: cover; display: block;">
      <img class="gatsby-resp-image-image" style="width: 100%; height: 100%; margin: 0; vertical-align: middle; position: absolute; top: 0; left: 0; box-shadow: inset 0px 0px 0px 400px white;" alt="word embedding markup feature" title="" src="./Turning Design Mockups Into Code With Deep Learning - FloydHub Blog_files/word_embedding_markup_feature-d4e76483527fefd10742c0ddc1cd3227-6c1a3.png" srcset="/static/word_embedding_markup_feature-d4e76483527fefd10742c0ddc1cd3227-4f362.png 192w,
/static/word_embedding_markup_feature-d4e76483527fefd10742c0ddc1cd3227-1883a.png 384w,
/static/word_embedding_markup_feature-d4e76483527fefd10742c0ddc1cd3227-6c1a3.png 768w,
/static/word_embedding_markup_feature-d4e76483527fefd10742c0ddc1cd3227-650d4.png 1152w,
/static/word_embedding_markup_feature-d4e76483527fefd10742c0ddc1cd3227-bbf5a.png 1536w,
/static/word_embedding_markup_feature-d4e76483527fefd10742c0ddc1cd3227-c6553.png 2304w,
/static/word_embedding_markup_feature-d4e76483527fefd10742c0ddc1cd3227-f669c.png 2637w" sizes="(max-width: 768px) 100vw, 768px">
    </span>
  </span>
  
  </a>
    
<br>
<p>To mix signals and find higher-level patterns we apply a TimeDistributed dense layer to the markup features. TimeDistributed dense is the same as a dense layer but with multiple inputs and outputs. </p>
<h5>Image features</h5>
<p>In parallel, we prepare the images. We take all the mini image features and transform them into one long list. The information is not changed, just reorganized. </p>

  <a class="gatsby-resp-image-link" href="https://blog.floydhub.com/static/image_feature_to_image_feature-77a1cf39ed251d4243b90325e60fbdf5-78710.png" style="display: block" target="_blank" rel="noopener">
  
  <span class="gatsby-resp-image-wrapper" style="position: relative; display: block; ; max-width: 768px; margin-left: auto; margin-right: auto;">
    <span class="gatsby-resp-image-background-image" style="padding-bottom: 22.35738255033557%; position: relative; bottom: 0; left: 0; background-image: url(&#39;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAECAYAAACOXx+WAAAACXBIWXMAAAsSAAALEgHS3X78AAAAyUlEQVQY022Pu0pDQRRF87ViFUgvYhNSpLKwsLAUxJBSYipRK/2QGe575s7c92PJGRREs+HAZnNm7TMLvhXHMVprlFI456jrms1tzGqjWa41N/cZVVVhrSXLMqIoCr7ve35r8WMEIotlWdJ1HcMwcHx3PB4MD0+G108fMilqmoZpmpjnOcxJoEC896RpGh61bcvhzbE/WnbPlpcPHzIplr2/oH9AkbTKlTLyvYvriPMrxdmlYnuXhkwKi6Igz/PgjTEkScI4joHxBXyYK8lbsYJZAAAAAElFTkSuQmCC&#39;); background-size: cover; display: block;">
      <img class="gatsby-resp-image-image" style="width: 100%; height: 100%; margin: 0; vertical-align: middle; position: absolute; top: 0; left: 0; box-shadow: inset 0px 0px 0px 400px white;" alt="image feature to image feature" title="" src="./Turning Design Mockups Into Code With Deep Learning - FloydHub Blog_files/image_feature_to_image_feature-77a1cf39ed251d4243b90325e60fbdf5-6c1a3.png" srcset="/static/image_feature_to_image_feature-77a1cf39ed251d4243b90325e60fbdf5-4f362.png 192w,
/static/image_feature_to_image_feature-77a1cf39ed251d4243b90325e60fbdf5-1883a.png 384w,
/static/image_feature_to_image_feature-77a1cf39ed251d4243b90325e60fbdf5-6c1a3.png 768w,
/static/image_feature_to_image_feature-77a1cf39ed251d4243b90325e60fbdf5-650d4.png 1152w,
/static/image_feature_to_image_feature-77a1cf39ed251d4243b90325e60fbdf5-bbf5a.png 1536w,
/static/image_feature_to_image_feature-77a1cf39ed251d4243b90325e60fbdf5-c6553.png 2304w,
/static/image_feature_to_image_feature-77a1cf39ed251d4243b90325e60fbdf5-78710.png 2384w" sizes="(max-width: 768px) 100vw, 768px">
    </span>
  </span>
  
  </a>
    
<br>
<p>Again, to mix signals and extract higher level notions, we apply a dense layer. Since we are only dealing with one input value, we can use a normal dense layer. To connect the image features to the markup features, we copy the image features. </p>
<p>In this case, we have three markup features. Thus, we end up with an equal amount of image features and markup features. </p>
<h5>Concatenating the image and markup features</h5>
<p>All the sentences are padded to create three markup features. Since we have prepared the image features, we can now add one image feature for each markup feature. </p>

  <a class="gatsby-resp-image-link" href="https://blog.floydhub.com/static/concatenate-747c07d8c62a2e026212d20860514188-78710.png" style="display: block" target="_blank" rel="noopener">
  
  <span class="gatsby-resp-image-wrapper" style="position: relative; display: block; ; max-width: 768px; margin-left: auto; margin-right: auto;">
    <span class="gatsby-resp-image-background-image" style="padding-bottom: 11.40939597315436%; position: relative; bottom: 0; left: 0; background-image: url(&#39;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAACCAYAAABYBvyLAAAACXBIWXMAAAsSAAALEgHS3X78AAAAgElEQVQI1x2LsQrDIBiE8/7P0dI1WrqWjrEQEEQ6VaegqMMfErSTV/yH47s77qZ1XTHPM6SUTCEEUymF1hpuD8L1TrhIwnM5uQshQGsNay2MMazhnXOYjuNAjBFEhJwzRi6loNaK3jsWXfF6n6zP98ddSgnee2zbxn7sx3ffd/wBx4+OrHSvFWcAAAAASUVORK5CYII=&#39;); background-size: cover; display: block;">
      <img class="gatsby-resp-image-image" style="width: 100%; height: 100%; margin: 0; vertical-align: middle; position: absolute; top: 0; left: 0; box-shadow: inset 0px 0px 0px 400px white;" alt="concatenate" title="" src="./Turning Design Mockups Into Code With Deep Learning - FloydHub Blog_files/concatenate-747c07d8c62a2e026212d20860514188-6c1a3.png" srcset="/static/concatenate-747c07d8c62a2e026212d20860514188-4f362.png 192w,
/static/concatenate-747c07d8c62a2e026212d20860514188-1883a.png 384w,
/static/concatenate-747c07d8c62a2e026212d20860514188-6c1a3.png 768w,
/static/concatenate-747c07d8c62a2e026212d20860514188-650d4.png 1152w,
/static/concatenate-747c07d8c62a2e026212d20860514188-bbf5a.png 1536w,
/static/concatenate-747c07d8c62a2e026212d20860514188-c6553.png 2304w,
/static/concatenate-747c07d8c62a2e026212d20860514188-78710.png 2384w" sizes="(max-width: 768px) 100vw, 768px">
    </span>
  </span>
  
  </a>
    
<br>
<p>After sticking one image feature to each markup feature, we end up with three image-markup features. This is the input we feed into the decoder. </p>
<h3>The Decoder</h3>
<p>Here we use the combined image-markup features to predict the next tag. </p>

  <a class="gatsby-resp-image-link" href="https://blog.floydhub.com/static/decoder-1592aedab9a95e07a513234aa258d777-524bf.png" style="display: block" target="_blank" rel="noopener">
  
  <span class="gatsby-resp-image-wrapper" style="position: relative; display: block; ; max-width: 768px; margin-left: auto; margin-right: auto;">
    <span class="gatsby-resp-image-background-image" style="padding-bottom: 20.243433696348497%; position: relative; bottom: 0; left: 0; background-image: url(&#39;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAECAYAAACOXx+WAAAACXBIWXMAAAsSAAALEgHS3X78AAAAfElEQVQY02P4jwMUdrz4n9n4DIwrel/+z2l+Ducv2fj2/5cvX7DqY8BlYGbDs/8JlU/BOKXmKZwNwvPWvP7/5MmT/y9evMAwGKeBkxa/+d8z7zUYT1v+9v+EhQj+ziMf/3///p00F/79+/f/v3//wBjkknfv3sH5IIwLAACAUCRrmRPpeQAAAABJRU5ErkJggg==&#39;); background-size: cover; display: block;">
      <img class="gatsby-resp-image-image" style="width: 100%; height: 100%; margin: 0; vertical-align: middle; position: absolute; top: 0; left: 0; box-shadow: inset 0px 0px 0px 400px white;" alt="decoder" title="" src="./Turning Design Mockups Into Code With Deep Learning - FloydHub Blog_files/decoder-1592aedab9a95e07a513234aa258d777-6c1a3.png" srcset="/static/decoder-1592aedab9a95e07a513234aa258d777-4f362.png 192w,
/static/decoder-1592aedab9a95e07a513234aa258d777-1883a.png 384w,
/static/decoder-1592aedab9a95e07a513234aa258d777-6c1a3.png 768w,
/static/decoder-1592aedab9a95e07a513234aa258d777-650d4.png 1152w,
/static/decoder-1592aedab9a95e07a513234aa258d777-bbf5a.png 1536w,
/static/decoder-1592aedab9a95e07a513234aa258d777-524bf.png 1561w" sizes="(max-width: 768px) 100vw, 768px">
    </span>
  </span>
  
  </a>
    
<br>
<p>In the below example, we use three image-markup feature pairs and output one next tag feature. </p>
<p>Note that the LSTM layer has the sequence set to false. Instead of returning the length of the input sequence it only predicts one feature. In our case, it’s a feature for the next tag. It contains the information for the final prediction. </p>

  <a class="gatsby-resp-image-link" href="https://blog.floydhub.com/static/image-markup-feature_to_vocab-eb39368b3f466914c9383d532675a622-99852.png" style="display: block" target="_blank" rel="noopener">
  
  <span class="gatsby-resp-image-wrapper" style="position: relative; display: block; ; max-width: 768px; margin-left: auto; margin-right: auto;">
    <span class="gatsby-resp-image-background-image" style="padding-bottom: 17.5%; position: relative; bottom: 0; left: 0; background-image: url(&#39;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAECAYAAACOXx+WAAAACXBIWXMAAAsSAAALEgHS3X78AAAA/UlEQVQY002PPUvDYACE+zMdnPwJDh0EBycHwUHsYgJZJDqY0MUSaEMpiClughLwIxpoqn1fjDHpW1Oa5NEELB4cN93DXcvzPAzDwHEc+v0+pmk2aVkWruuSxG+cX8ZsbE/Y2onYbEe0D6aMxhFj74pOp4Ou62ia1mQrSRJqZ1lGURRUVUVZlmvXimeKx1vJk5/w/PrNZLZCLVbM51nTVUqtey3+qV5k2za9Xo9ut8twOORDThlcf7F7JNg/kewdCw4Nwf1DwjJfNMAa9qc1sF4XBAG+7xOGIVEUIYSgLJbcvShOB4IzV3LhfjK6UbzL/PdVipSSNE3J87zh/ACAdRpy63A9PQAAAABJRU5ErkJggg==&#39;); background-size: cover; display: block;">
      <img class="gatsby-resp-image-image" style="width: 100%; height: 100%; margin: 0; vertical-align: middle; position: absolute; top: 0; left: 0; box-shadow: inset 0px 0px 0px 400px white;" alt="image markup feature to vocab" title="" src="./Turning Design Mockups Into Code With Deep Learning - FloydHub Blog_files/image-markup-feature_to_vocab-eb39368b3f466914c9383d532675a622-6c1a3.png" srcset="/static/image-markup-feature_to_vocab-eb39368b3f466914c9383d532675a622-4f362.png 192w,
/static/image-markup-feature_to_vocab-eb39368b3f466914c9383d532675a622-1883a.png 384w,
/static/image-markup-feature_to_vocab-eb39368b3f466914c9383d532675a622-6c1a3.png 768w,
/static/image-markup-feature_to_vocab-eb39368b3f466914c9383d532675a622-650d4.png 1152w,
/static/image-markup-feature_to_vocab-eb39368b3f466914c9383d532675a622-bbf5a.png 1536w,
/static/image-markup-feature_to_vocab-eb39368b3f466914c9383d532675a622-99852.png 2200w" sizes="(max-width: 768px) 100vw, 768px">
    </span>
  </span>
  
  </a>
    
<h5>The final prediction</h5>
<p>The dense layer works like a traditional feedforward neural network. It connects the 512 digits in the next tag feature with the 4 final predictions. Say we have 4 words in our vocabulary: start, hello, world, and end. </p>
<p>The vocabulary prediction could be [0.1, 0.1, 0.1, 0.7]. The softmax activation in the dense layer distributes a probability from 0 - 1, with the sum of all predictions equal to 1. In this case, it predicts that the 4th word is the next tag. Then you translate the one-hot encoding [0, 0, 0, 1] into the mapped value, say “end”. </p>
<div class="gatsby-highlight">
      <pre class="language-python"><code>    <span class="token comment" spellcheck="true"># Load the images and preprocess them for inception-resnet</span>
    images <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
    all_filenames <span class="token operator">=</span> listdir<span class="token punctuation">(</span><span class="token string">'images/'</span><span class="token punctuation">)</span>
    all_filenames<span class="token punctuation">.</span>sort<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">for</span> filename <span class="token keyword">in</span> all_filenames<span class="token punctuation">:</span>
        images<span class="token punctuation">.</span>append<span class="token punctuation">(</span>img_to_array<span class="token punctuation">(</span>load_img<span class="token punctuation">(</span><span class="token string">'images/'</span><span class="token operator">+</span>filename<span class="token punctuation">,</span> target_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">299</span><span class="token punctuation">,</span> <span class="token number">299</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    images <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>images<span class="token punctuation">,</span> dtype<span class="token operator">=</span>float<span class="token punctuation">)</span>
    images <span class="token operator">=</span> preprocess_input<span class="token punctuation">(</span>images<span class="token punctuation">)</span>
    
    <span class="token comment" spellcheck="true"># Run the images through inception-resnet and extract the features without the classification layer</span>
    IR2 <span class="token operator">=</span> InceptionResNetV2<span class="token punctuation">(</span>weights<span class="token operator">=</span><span class="token string">'imagenet'</span><span class="token punctuation">,</span> include_top<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
    features <span class="token operator">=</span> IR2<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>images<span class="token punctuation">)</span>
    
    
    <span class="token comment" spellcheck="true"># We will cap each input sequence to 100 tokens</span>
    max_caption_len <span class="token operator">=</span> <span class="token number">100</span>
    <span class="token comment" spellcheck="true"># Initialize the function that will create our vocabulary </span>
    tokenizer <span class="token operator">=</span> Tokenizer<span class="token punctuation">(</span>filters<span class="token operator">=</span><span class="token string">''</span><span class="token punctuation">,</span> split<span class="token operator">=</span><span class="token string">" "</span><span class="token punctuation">,</span> lower<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
    
    <span class="token comment" spellcheck="true"># Read a document and return a string</span>
    <span class="token keyword">def</span> <span class="token function">load_doc</span><span class="token punctuation">(</span>filename<span class="token punctuation">)</span><span class="token punctuation">:</span>
        file <span class="token operator">=</span> open<span class="token punctuation">(</span>filename<span class="token punctuation">,</span> <span class="token string">'r'</span><span class="token punctuation">)</span>
        text <span class="token operator">=</span> file<span class="token punctuation">.</span>read<span class="token punctuation">(</span><span class="token punctuation">)</span>
        file<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token keyword">return</span> text
    
    <span class="token comment" spellcheck="true"># Load all the HTML files</span>
    X <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
    all_filenames <span class="token operator">=</span> listdir<span class="token punctuation">(</span><span class="token string">'html/'</span><span class="token punctuation">)</span>
    all_filenames<span class="token punctuation">.</span>sort<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">for</span> filename <span class="token keyword">in</span> all_filenames<span class="token punctuation">:</span>
        X<span class="token punctuation">.</span>append<span class="token punctuation">(</span>load_doc<span class="token punctuation">(</span><span class="token string">'html/'</span><span class="token operator">+</span>filename<span class="token punctuation">)</span><span class="token punctuation">)</span>
    
    <span class="token comment" spellcheck="true"># Create the vocabulary from the html files</span>
    tokenizer<span class="token punctuation">.</span>fit_on_texts<span class="token punctuation">(</span>X<span class="token punctuation">)</span>
    
    <span class="token comment" spellcheck="true"># Add +1 to leave space for empty words</span>
    vocab_size <span class="token operator">=</span> len<span class="token punctuation">(</span>tokenizer<span class="token punctuation">.</span>word_index<span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token number">1</span>
    <span class="token comment" spellcheck="true"># Translate each word in text file to the matching vocabulary index</span>
    sequences <span class="token operator">=</span> tokenizer<span class="token punctuation">.</span>texts_to_sequences<span class="token punctuation">(</span>X<span class="token punctuation">)</span>
    <span class="token comment" spellcheck="true"># The longest HTML file</span>
    max_length <span class="token operator">=</span> max<span class="token punctuation">(</span>len<span class="token punctuation">(</span>s<span class="token punctuation">)</span> <span class="token keyword">for</span> s <span class="token keyword">in</span> sequences<span class="token punctuation">)</span>
    
    <span class="token comment" spellcheck="true"># Intialize our final input to the model</span>
    X<span class="token punctuation">,</span> y<span class="token punctuation">,</span> image_data <span class="token operator">=</span> list<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> list<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> list<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">for</span> img_no<span class="token punctuation">,</span> seq <span class="token keyword">in</span> enumerate<span class="token punctuation">(</span>sequences<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> len<span class="token punctuation">(</span>seq<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token comment" spellcheck="true"># Add the entire sequence to the input and only keep the next word for the output</span>
            in_seq<span class="token punctuation">,</span> out_seq <span class="token operator">=</span> seq<span class="token punctuation">[</span><span class="token punctuation">:</span>i<span class="token punctuation">]</span><span class="token punctuation">,</span> seq<span class="token punctuation">[</span>i<span class="token punctuation">]</span>
            <span class="token comment" spellcheck="true"># If the sentence is shorter than max_length, fill it up with empty words</span>
            in_seq <span class="token operator">=</span> pad_sequences<span class="token punctuation">(</span><span class="token punctuation">[</span>in_seq<span class="token punctuation">]</span><span class="token punctuation">,</span> maxlen<span class="token operator">=</span>max_length<span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
            <span class="token comment" spellcheck="true"># Map the output to one-hot encoding</span>
            out_seq <span class="token operator">=</span> to_categorical<span class="token punctuation">(</span><span class="token punctuation">[</span>out_seq<span class="token punctuation">]</span><span class="token punctuation">,</span> num_classes<span class="token operator">=</span>vocab_size<span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
            <span class="token comment" spellcheck="true"># Add and image corresponding to the HTML file</span>
            image_data<span class="token punctuation">.</span>append<span class="token punctuation">(</span>features<span class="token punctuation">[</span>img_no<span class="token punctuation">]</span><span class="token punctuation">)</span>
            <span class="token comment" spellcheck="true"># Cut the input sentence to 100 tokens, and add it to the input data</span>
            X<span class="token punctuation">.</span>append<span class="token punctuation">(</span>in_seq<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">100</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
            y<span class="token punctuation">.</span>append<span class="token punctuation">(</span>out_seq<span class="token punctuation">)</span>
    
    X<span class="token punctuation">,</span> y<span class="token punctuation">,</span> image_data <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>X<span class="token punctuation">)</span><span class="token punctuation">,</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>y<span class="token punctuation">)</span><span class="token punctuation">,</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>image_data<span class="token punctuation">)</span>
    
    <span class="token comment" spellcheck="true"># Create the encoder</span>
    image_features <span class="token operator">=</span> Input<span class="token punctuation">(</span>shape<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">8</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">,</span> <span class="token number">1536</span><span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    image_flat <span class="token operator">=</span> Flatten<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">(</span>image_features<span class="token punctuation">)</span>
    image_flat <span class="token operator">=</span> Dense<span class="token punctuation">(</span><span class="token number">128</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">'relu'</span><span class="token punctuation">)</span><span class="token punctuation">(</span>image_flat<span class="token punctuation">)</span>
    ir2_out <span class="token operator">=</span> RepeatVector<span class="token punctuation">(</span>max_caption_len<span class="token punctuation">)</span><span class="token punctuation">(</span>image_flat<span class="token punctuation">)</span>
    
    language_input <span class="token operator">=</span> Input<span class="token punctuation">(</span>shape<span class="token operator">=</span><span class="token punctuation">(</span>max_caption_len<span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    language_model <span class="token operator">=</span> Embedding<span class="token punctuation">(</span>vocab_size<span class="token punctuation">,</span> <span class="token number">200</span><span class="token punctuation">,</span> input_length<span class="token operator">=</span>max_caption_len<span class="token punctuation">)</span><span class="token punctuation">(</span>language_input<span class="token punctuation">)</span>
    language_model <span class="token operator">=</span> LSTM<span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">,</span> return_sequences<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">(</span>language_model<span class="token punctuation">)</span>
    language_model <span class="token operator">=</span> LSTM<span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">,</span> return_sequences<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">(</span>language_model<span class="token punctuation">)</span>
    language_model <span class="token operator">=</span> TimeDistributed<span class="token punctuation">(</span>Dense<span class="token punctuation">(</span><span class="token number">128</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">'relu'</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">(</span>language_model<span class="token punctuation">)</span>
    
    <span class="token comment" spellcheck="true"># Create the decoder</span>
    decoder <span class="token operator">=</span> concatenate<span class="token punctuation">(</span><span class="token punctuation">[</span>ir2_out<span class="token punctuation">,</span> language_model<span class="token punctuation">]</span><span class="token punctuation">)</span>
    decoder <span class="token operator">=</span> LSTM<span class="token punctuation">(</span><span class="token number">512</span><span class="token punctuation">,</span> return_sequences<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">(</span>decoder<span class="token punctuation">)</span>
    decoder_output <span class="token operator">=</span> Dense<span class="token punctuation">(</span>vocab_size<span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">'softmax'</span><span class="token punctuation">)</span><span class="token punctuation">(</span>decoder<span class="token punctuation">)</span>
    
    <span class="token comment" spellcheck="true"># Compile the model</span>
    model <span class="token operator">=</span> Model<span class="token punctuation">(</span>inputs<span class="token operator">=</span><span class="token punctuation">[</span>image_features<span class="token punctuation">,</span> language_input<span class="token punctuation">]</span><span class="token punctuation">,</span> outputs<span class="token operator">=</span>decoder_output<span class="token punctuation">)</span>
    model<span class="token punctuation">.</span>compile<span class="token punctuation">(</span>loss<span class="token operator">=</span><span class="token string">'categorical_crossentropy'</span><span class="token punctuation">,</span> optimizer<span class="token operator">=</span><span class="token string">'rmsprop'</span><span class="token punctuation">)</span>
    
    <span class="token comment" spellcheck="true"># Train the neural network</span>
    model<span class="token punctuation">.</span>fit<span class="token punctuation">(</span><span class="token punctuation">[</span>image_data<span class="token punctuation">,</span> X<span class="token punctuation">]</span><span class="token punctuation">,</span> y<span class="token punctuation">,</span> batch_size<span class="token operator">=</span><span class="token number">64</span><span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> epochs<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>
    
    <span class="token comment" spellcheck="true"># map an integer to a word</span>
    <span class="token keyword">def</span> <span class="token function">word_for_id</span><span class="token punctuation">(</span>integer<span class="token punctuation">,</span> tokenizer<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">for</span> word<span class="token punctuation">,</span> index <span class="token keyword">in</span> tokenizer<span class="token punctuation">.</span>word_index<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token keyword">if</span> index <span class="token operator">==</span> integer<span class="token punctuation">:</span>
                <span class="token keyword">return</span> word
        <span class="token keyword">return</span> None
    
    <span class="token comment" spellcheck="true"># generate a description for an image</span>
    <span class="token keyword">def</span> <span class="token function">generate_desc</span><span class="token punctuation">(</span>model<span class="token punctuation">,</span> tokenizer<span class="token punctuation">,</span> photo<span class="token punctuation">,</span> max_length<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment" spellcheck="true"># seed the generation process</span>
        in_text <span class="token operator">=</span> <span class="token string">'START'</span>
        <span class="token comment" spellcheck="true"># iterate over the whole length of the sequence</span>
        <span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">900</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token comment" spellcheck="true"># integer encode input sequence</span>
            sequence <span class="token operator">=</span> tokenizer<span class="token punctuation">.</span>texts_to_sequences<span class="token punctuation">(</span><span class="token punctuation">[</span>in_text<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">100</span><span class="token punctuation">:</span><span class="token punctuation">]</span>
            <span class="token comment" spellcheck="true"># pad input</span>
            sequence <span class="token operator">=</span> pad_sequences<span class="token punctuation">(</span><span class="token punctuation">[</span>sequence<span class="token punctuation">]</span><span class="token punctuation">,</span> maxlen<span class="token operator">=</span>max_length<span class="token punctuation">)</span>
            <span class="token comment" spellcheck="true"># predict next word</span>
            yhat <span class="token operator">=</span> model<span class="token punctuation">.</span>predict<span class="token punctuation">(</span><span class="token punctuation">[</span>photo<span class="token punctuation">,</span>sequence<span class="token punctuation">]</span><span class="token punctuation">,</span> verbose<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
            <span class="token comment" spellcheck="true"># convert probability to integer</span>
            yhat <span class="token operator">=</span> np<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>yhat<span class="token punctuation">)</span>
            <span class="token comment" spellcheck="true"># map integer to word</span>
            word <span class="token operator">=</span> word_for_id<span class="token punctuation">(</span>yhat<span class="token punctuation">,</span> tokenizer<span class="token punctuation">)</span>
            <span class="token comment" spellcheck="true"># stop if we cannot map the word</span>
            <span class="token keyword">if</span> word <span class="token keyword">is</span> None<span class="token punctuation">:</span>
                <span class="token keyword">break</span>
            <span class="token comment" spellcheck="true"># append as input for generating the next word</span>
            in_text <span class="token operator">+=</span> <span class="token string">' '</span> <span class="token operator">+</span> word
            <span class="token comment" spellcheck="true"># Print the prediction</span>
            <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">' '</span> <span class="token operator">+</span> word<span class="token punctuation">,</span> end<span class="token operator">=</span><span class="token string">''</span><span class="token punctuation">)</span>
            <span class="token comment" spellcheck="true"># stop if we predict the end of the sequence</span>
            <span class="token keyword">if</span> word <span class="token operator">==</span> <span class="token string">'END'</span><span class="token punctuation">:</span>
                <span class="token keyword">break</span>
        <span class="token keyword">return</span>
    
    <span class="token comment" spellcheck="true"># Load and image, preprocess it for IR2, extract features and generate the HTML</span>
    test_image <span class="token operator">=</span> img_to_array<span class="token punctuation">(</span>load_img<span class="token punctuation">(</span><span class="token string">'images/87.jpg'</span><span class="token punctuation">,</span> target_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">299</span><span class="token punctuation">,</span> <span class="token number">299</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    test_image <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>test_image<span class="token punctuation">,</span> dtype<span class="token operator">=</span>float<span class="token punctuation">)</span>
    test_image <span class="token operator">=</span> preprocess_input<span class="token punctuation">(</span>test_image<span class="token punctuation">)</span>
    test_features <span class="token operator">=</span> IR2<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span>test_image<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    generate_desc<span class="token punctuation">(</span>model<span class="token punctuation">,</span> tokenizer<span class="token punctuation">,</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>test_features<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">)</span>
</code></pre>
      </div>
<h3>Output</h3>

  <a class="gatsby-resp-image-link" href="https://blog.floydhub.com/static/html_output-ba7571455ed0209f2d98b2cd1f94b9df-ef96e.png" style="display: block" target="_blank" rel="noopener">
  
  <span class="gatsby-resp-image-wrapper" style="position: relative; display: block; ; max-width: 768px; margin-left: auto; margin-right: auto;">
    <span class="gatsby-resp-image-background-image" style="padding-bottom: 26.015624999999996%; position: relative; bottom: 0; left: 0; background-image: url(&#39;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAFCAYAAABFA8wzAAAACXBIWXMAAAsSAAALEgHS3X78AAAAyElEQVQY05VQuw6DMAzM/4+M/AFDKSNM9A+YYKUwUN5UggQIjytOW0QlllqyrLv4znZYVVVI0xRFUajs+x6cczTPRlVKKeXGC3Rdp3D7qUmSwL25sG0bjuMgCHywOH6ohzzPUdc1xnHEPM84BmEyPQZh4kmnaRp0XVeYcSGxruuP+B9Dui7wfdzD8G14Jj7jaPNlWfYkHEURLOsKwzBgmhd4ngc2TZM6NcuyXUQGbduq6UIIxQ3DgLIsEW6bfP+aLqNNSUv91PcCZ8V8pSKRD6cAAAAASUVORK5CYII=&#39;); background-size: cover; display: block;">
      <img class="gatsby-resp-image-image" style="width: 100%; height: 100%; margin: 0; vertical-align: middle; position: absolute; top: 0; left: 0; box-shadow: inset 0px 0px 0px 400px white;" alt="html output" title="" src="./Turning Design Mockups Into Code With Deep Learning - FloydHub Blog_files/html_output-ba7571455ed0209f2d98b2cd1f94b9df-6c1a3.png" srcset="/static/html_output-ba7571455ed0209f2d98b2cd1f94b9df-4f362.png 192w,
/static/html_output-ba7571455ed0209f2d98b2cd1f94b9df-1883a.png 384w,
/static/html_output-ba7571455ed0209f2d98b2cd1f94b9df-6c1a3.png 768w,
/static/html_output-ba7571455ed0209f2d98b2cd1f94b9df-650d4.png 1152w,
/static/html_output-ba7571455ed0209f2d98b2cd1f94b9df-bbf5a.png 1536w,
/static/html_output-ba7571455ed0209f2d98b2cd1f94b9df-c6553.png 2304w,
/static/html_output-ba7571455ed0209f2d98b2cd1f94b9df-ef96e.png 3840w" sizes="(max-width: 768px) 100vw, 768px">
    </span>
  </span>
  
  </a>
    
<h4>Links to generated websites</h4>
<ul>
<li><a href="https://emilwallner.github.io/html/250_epochs/">250 epochs</a></li>
<li><a href="https://emilwallner.github.io/html/350_epochs/">350 epochs</a></li>
<li><a href="https://emilwallner.github.io/html/450_epochs/">450 epochs</a></li>
<li><a href="https://emilwallner.github.io/html/550_epochs/">550 epochs</a></li>
</ul>
<p>If you can’t see anything when you click these links, you can right click and click on ‘View Page Source’. Here is the <a href="https://emilwallner.github.io/html/Original/">original website</a> for reference.</p>
<h3>Mistakes I made:</h3>
<ul>
<li><strong>LSTMs are a lot heavier for my cognition compared to CNNs</strong>. When I unrolled all the LSTMs they became easier to understand. <a href="http://course.fast.ai/lessons/lesson6.html">Fast.ai’s video on RNNs</a> was super useful. Also, focus on the input and output features before you try understanding how they work. </li>
<li><strong>Building a vocabulary from the ground up is a lot easier than narrowing down a huge vocabulary.</strong> This includes everything from fonts, div sizes, hex colors to variable names and normal words. </li>
<li><strong>Most of the libraries are created to parse text documents and not code.</strong> In documents, everything is separated by a space, but in code, you need custom parsing. </li>
<li><strong>You can extract features with a model that’s trained on Imagenet.</strong>  This might seem counterintuitive since Imagenet has few web images. However, the loss is 30% higher compared to to a pix2code model, which is trained from scratch. I’d be interesting to use a pre-train inception-resnet type of model based on web screenshots. </li>
</ul>
<h1>Bootstrap version</h1>
<p>In our final version, we’ll use a dataset of generated bootstrap websites from the <a href="https://arxiv.org/abs/1705.07962">pix2code paper.</a> By using Twitter’s <a href="https://getbootstrap.com/">bootstrap</a>, we can combine HTML and CSS and decrease the size of the vocabulary. </p>
<p>We’ll enable it to generate the markup for a screenshot it has not seen before. We’ll also dig into how it builds knowledge about the screenshot and markup. </p>
<p>Instead of training it on the bootstrap markup, we’ll use 17 simplified tokens that we then translate into HTML and CSS. <a href="https://github.com/tonybeltramelli/pix2code/tree/master/datasets">The dataset</a> includes 1500 test screenshots and 250 validation images. For each screenshot there are on average 65 tokens, resulting in 96925 training examples.  </p>
<p>By tweaking the model in the pix2code paper, the model can predict the web components with 97% accuracy (BLEU 4-ngram greedy search, more on this later). </p>
<img src="./Turning Design Mockups Into Code With Deep Learning - FloydHub Blog_files/bootstrap_overview-99e7deb3c036ab6d5def0ab33f2e4d69.gif" style="width: 768px;">
<h4>An end-to-end approach</h4>
<p>Extracting features from pre-trained models works well in image captioning models. But after a few experiments, I realized that pix2code’s end-to-end approach works better for this problem. The pre-trained models have not been trained on web data and are customized for classification. </p>
<p>In this model, we replace the pre-trained image features with a light convolutional neural network. Instead of using max-pooling to increase information density, we increase the strides. This maintains the position and the color of the front-end elements. </p>

  <a class="gatsby-resp-image-link" href="https://blog.floydhub.com/static/model_more_detail_alone-bfbf97a5ec65ff255f35a8e3cd2069e0-2b038.png" style="display: block" target="_blank" rel="noopener">
  
  <span class="gatsby-resp-image-wrapper" style="position: relative; display: block; ; max-width: 768px; margin-left: auto; margin-right: auto;">
    <span class="gatsby-resp-image-background-image" style="padding-bottom: 34.98014997794442%; position: relative; bottom: 0; left: 0; background-image: url(&#39;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAHCAYAAAAIy204AAAACXBIWXMAAAsSAAALEgHS3X78AAAAoElEQVQoz2P4jwP8+fPn//v37/9//vz5/5cvX/5/+PDh/7dv3/4TAgy4JLYc+PQ/v/X5/8zGZ/8757z+3zL99f9FGz+Qb+DaXR//p9Q8/R9f8fR/QRvQ4IZn//sXvCHfwM37P/3PABpS1PHif2nXi/+5Lc//T1v2jnwDtx36DDaksP0FGIPYM1dSw0CgC0GYYgP//fsHxqCYBcU0jE8IAAAWOA9Xh1ztOgAAAABJRU5ErkJggg==&#39;); background-size: cover; display: block;">
      <img class="gatsby-resp-image-image" style="width: 100%; height: 100%; margin: 0; vertical-align: middle; position: absolute; top: 0; left: 0; box-shadow: inset 0px 0px 0px 400px white;" alt="model more detail alone" title="" src="./Turning Design Mockups Into Code With Deep Learning - FloydHub Blog_files/model_more_detail_alone-bfbf97a5ec65ff255f35a8e3cd2069e0-6c1a3.png" srcset="/static/model_more_detail_alone-bfbf97a5ec65ff255f35a8e3cd2069e0-4f362.png 192w,
/static/model_more_detail_alone-bfbf97a5ec65ff255f35a8e3cd2069e0-1883a.png 384w,
/static/model_more_detail_alone-bfbf97a5ec65ff255f35a8e3cd2069e0-6c1a3.png 768w,
/static/model_more_detail_alone-bfbf97a5ec65ff255f35a8e3cd2069e0-650d4.png 1152w,
/static/model_more_detail_alone-bfbf97a5ec65ff255f35a8e3cd2069e0-bbf5a.png 1536w,
/static/model_more_detail_alone-bfbf97a5ec65ff255f35a8e3cd2069e0-2b038.png 2267w" sizes="(max-width: 768px) 100vw, 768px">
    </span>
  </span>
  
  </a>
    
<br>
<p>There are two core models that enable this: convolutional neural networks (CNN) and recurrent neural networks (RNN). The most common recurrent neural network is long-short term memory (LSTM), so that’s what I’ll refer to.  </p>
<p>There are plenty of great CNN tutorials and I covered them in <a href="https://blog.floydhub.com/colorizing-b&amp;w-photos-with-neural-networks/">my previous article</a>. Here, I’ll focus on the LSTMs. </p>
<h4>Understanding timesteps in LSTMs</h4>
<p>One of the harder things to grasp about LSTMs is timesteps. A vanilla neural network can be thought of as two timesteps. If you give it “Hello”, it predicts “World”. But it would struggle to predict more timesteps. In the below example, the input has four timesteps, one for each word.</p>
<p>LSTMs are made for input with timesteps. It’s a neural network customized for information in order. If you unroll our model it looks like this. For each downward step, you keep the same weights. You apply one set of weights to the previous output and another set to the new input.  </p>

  <a class="gatsby-resp-image-link" href="https://blog.floydhub.com/static/lstm_timesteps-51b6eece9c5e6abe2cc16b0dcac6eb53-ef96e.png" style="display: block" target="_blank" rel="noopener">
  
  <span class="gatsby-resp-image-wrapper" style="position: relative; display: block; ; max-width: 768px; margin-left: auto; margin-right: auto;">
    <span class="gatsby-resp-image-background-image" style="padding-bottom: 66.40625%; position: relative; bottom: 0; left: 0; background-image: url(&#39;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAANCAYAAACpUE5eAAAACXBIWXMAAAsSAAALEgHS3X78AAABFElEQVQ4y41Tiw6DIAzc/3+piU4FobztekzcYpYJSVPA9trr4YMvK4TA+75323U9+MdCoDHmPLd9zpmdczxNE1P0fYDoEIlaa7YUxZKAeLkrHFPiEGPdu17AKAkwZ2wFhuGcBKxZKYXz4f8CItFaW7t8Pmem5JlyYEOWU8nSXWDvfe0U1G8B2/zec1rPzpZ1rR7FtN6YiFgp3UcZVQE4z/NJH/sGqJQ6AFUf4La9O1iWpYpCrsjZfUQJhyhS9BYQAaiM4CizqsMXUdJFlCqW+FtAiLHKvKoo83qKQl46LOgwspdvzXdRBl0Aank2LcEYOhmQ3Nc7a/sBYeM41icCet8eDOCHYeh7NgiCMPhT/hlifgG+AJMFABZ22OncAAAAAElFTkSuQmCC&#39;); background-size: cover; display: block;">
      <img class="gatsby-resp-image-image" style="width: 100%; height: 100%; margin: 0; vertical-align: middle; position: absolute; top: 0; left: 0; box-shadow: inset 0px 0px 0px 400px white;" alt="lstm timesteps" title="" src="./Turning Design Mockups Into Code With Deep Learning - FloydHub Blog_files/lstm_timesteps-51b6eece9c5e6abe2cc16b0dcac6eb53-6c1a3.png" srcset="/static/lstm_timesteps-51b6eece9c5e6abe2cc16b0dcac6eb53-4f362.png 192w,
/static/lstm_timesteps-51b6eece9c5e6abe2cc16b0dcac6eb53-1883a.png 384w,
/static/lstm_timesteps-51b6eece9c5e6abe2cc16b0dcac6eb53-6c1a3.png 768w,
/static/lstm_timesteps-51b6eece9c5e6abe2cc16b0dcac6eb53-650d4.png 1152w,
/static/lstm_timesteps-51b6eece9c5e6abe2cc16b0dcac6eb53-bbf5a.png 1536w,
/static/lstm_timesteps-51b6eece9c5e6abe2cc16b0dcac6eb53-c6553.png 2304w,
/static/lstm_timesteps-51b6eece9c5e6abe2cc16b0dcac6eb53-ef96e.png 3840w" sizes="(max-width: 768px) 100vw, 768px">
    </span>
  </span>
  
  </a>
    
<p>The weighted input and output are concatenated and added together with an activation. This is the output for that timestep. Since we reuse the weights, they draw information from several inputs and build knowledge of the sequence. </p>
<p>Here is a simplified version of the process for each timestep in an LSTM. </p>

  <a class="gatsby-resp-image-link" href="https://blog.floydhub.com/static/rnn_example-385ca1843bf3d88e93eec3294fcbb13c-ef96e.png" style="display: block" target="_blank" rel="noopener">
  
  <span class="gatsby-resp-image-wrapper" style="position: relative; display: block; ; max-width: 768px; margin-left: auto; margin-right: auto;">
    <span class="gatsby-resp-image-background-image" style="padding-bottom: 21.770833333333332%; position: relative; bottom: 0; left: 0; background-image: url(&#39;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAECAYAAACOXx+WAAAACXBIWXMAAAsSAAALEgHS3X78AAAAoUlEQVQY04VQ7QqDMAz0jfcae6jtBfZnwqA/ZCrFlmpXBZmo/TC32r8TPAi5BHKXJMMBvPfgnENKiTp/oW1bKKWgYq21BhGBti0G/c1mR4LGGJRlCdE0+Fyu6LoOzjkEPSSTnfvxC5rmc0HuDG7vBxhjqKsK6pmjitlai2mZUBRF4n61oBDOBdkqcVc5hBBpM7UM6Ps+vWEMc+rtfIsnH+EHjaYzzidbZ5kAAAAASUVORK5CYII=&#39;); background-size: cover; display: block;">
      <img class="gatsby-resp-image-image" style="width: 100%; height: 100%; margin: 0; vertical-align: middle; position: absolute; top: 0; left: 0; box-shadow: inset 0px 0px 0px 400px white;" alt="rnn example" title="" src="./Turning Design Mockups Into Code With Deep Learning - FloydHub Blog_files/rnn_example-385ca1843bf3d88e93eec3294fcbb13c-6c1a3.png" srcset="/static/rnn_example-385ca1843bf3d88e93eec3294fcbb13c-4f362.png 192w,
/static/rnn_example-385ca1843bf3d88e93eec3294fcbb13c-1883a.png 384w,
/static/rnn_example-385ca1843bf3d88e93eec3294fcbb13c-6c1a3.png 768w,
/static/rnn_example-385ca1843bf3d88e93eec3294fcbb13c-650d4.png 1152w,
/static/rnn_example-385ca1843bf3d88e93eec3294fcbb13c-bbf5a.png 1536w,
/static/rnn_example-385ca1843bf3d88e93eec3294fcbb13c-c6553.png 2304w,
/static/rnn_example-385ca1843bf3d88e93eec3294fcbb13c-ef96e.png 3840w" sizes="(max-width: 768px) 100vw, 768px">
    </span>
  </span>
  
  </a>
    
<br>
<p>To get a feel for this logic, I’d recommend building an RNN from scratch with Andrew Trask’s <a href="https://iamtrask.github.io/2015/11/15/anyone-can-code-lstm/">brilliant tutorial</a>. </p>
<h4>Understanding the units in LSTM layers</h4>
<p>The amount of units in each LSTM layer determines it’s ability to memorize. This also corresponds to the size of each output feature. Again, a feature is a long list of numbers used to transfer information between layers.  </p>
<p>Each unit in the LSTM layer learns to keep track of different aspects of the syntax. Below is a visualization of a unit that keeps tracks of the information in the row div. This is the simplified markup we are using to train the bootstrap model.  </p>

  <a class="gatsby-resp-image-link" href="https://blog.floydhub.com/static/lstm_cell_activation-1a1842b595ea638407a7389e26aa699b-ef96e.png" style="display: block" target="_blank" rel="noopener">
  
  <span class="gatsby-resp-image-wrapper" style="position: relative; display: block; ; max-width: 768px; margin-left: auto; margin-right: auto;">
    <span class="gatsby-resp-image-background-image" style="padding-bottom: 13.28125%; position: relative; bottom: 0; left: 0; background-image: url(&#39;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAADCAYAAACTWi8uAAAACXBIWXMAAAsSAAALEgHS3X78AAAA3klEQVQI1yXMTUvCcADHcV9fB50GvYDeQLTpcEtsqdg50Ay09TSwh0N0UDFXDVEUFSVtJh2KCi8ieM7Lt7/uB18+t5+v2pqiHbdQs13UTEfoFc31hT2iIqsxwvqy2RteortX6ML4pEhyfEfKvSXdv8f5dlnNV/x02CwbSM8HSLawZhBykgQe9wlUvfzlGP5KnOBLglA9hfRksFVLs2PnCTdP2CjpbHePvMOH3zbah4Xyfo78WiA8XnnK7iCPMjLXykOTyOQCxT1DfiugNm7QzDaH1z1mLPj5mzNdLtaH/2j4sJ8KvvbEAAAAAElFTkSuQmCC&#39;); background-size: cover; display: block;">
      <img class="gatsby-resp-image-image" style="width: 100%; height: 100%; margin: 0; vertical-align: middle; position: absolute; top: 0; left: 0; box-shadow: inset 0px 0px 0px 400px white;" alt="lstm cell activation" title="" src="./Turning Design Mockups Into Code With Deep Learning - FloydHub Blog_files/lstm_cell_activation-1a1842b595ea638407a7389e26aa699b-6c1a3.png" srcset="/static/lstm_cell_activation-1a1842b595ea638407a7389e26aa699b-4f362.png 192w,
/static/lstm_cell_activation-1a1842b595ea638407a7389e26aa699b-1883a.png 384w,
/static/lstm_cell_activation-1a1842b595ea638407a7389e26aa699b-6c1a3.png 768w,
/static/lstm_cell_activation-1a1842b595ea638407a7389e26aa699b-650d4.png 1152w,
/static/lstm_cell_activation-1a1842b595ea638407a7389e26aa699b-bbf5a.png 1536w,
/static/lstm_cell_activation-1a1842b595ea638407a7389e26aa699b-c6553.png 2304w,
/static/lstm_cell_activation-1a1842b595ea638407a7389e26aa699b-ef96e.png 3840w" sizes="(max-width: 768px) 100vw, 768px">
    </span>
  </span>
  
  </a>
    
<br>
<p>Each LSTM unit maintains a cell state. Think of the cell state as the memory. The weights and activations are used to modify the state in different ways. This enables the LSTM layers to fine tune which information to keep and discard for each input. </p>
<p>In addition to passing through an output feature for each input it also forwards the cell states, one value for each unit in the LSTM. To get a feel for how the components within the LSTM interacts, I recommend <a href="https://colah.github.io/posts/2015-08-Understanding-LSTMs/">Colah’s tutorial</a>, Jayasiri’s <a href="http://blog.varunajayasiri.com/numpy_lstm.html">Numpy implementation</a>, and <a href="https://www.youtube.com/watch?v=yCC09vCHzF8">Karphay’s lecture</a> and <a href="https://karpathy.github.io/2015/05/21/rnn-effectiveness/">write-up.</a> </p>
<div class="gatsby-highlight">
      <pre class="language-python"><code>    dir_name <span class="token operator">=</span> <span class="token string">'resources/eval_light/'</span>
    
    <span class="token comment" spellcheck="true"># Read a file and return a string</span>
    <span class="token keyword">def</span> <span class="token function">load_doc</span><span class="token punctuation">(</span>filename<span class="token punctuation">)</span><span class="token punctuation">:</span>
        file <span class="token operator">=</span> open<span class="token punctuation">(</span>filename<span class="token punctuation">,</span> <span class="token string">'r'</span><span class="token punctuation">)</span>
        text <span class="token operator">=</span> file<span class="token punctuation">.</span>read<span class="token punctuation">(</span><span class="token punctuation">)</span>
        file<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token keyword">return</span> text
    
    <span class="token keyword">def</span> <span class="token function">load_data</span><span class="token punctuation">(</span>data_dir<span class="token punctuation">)</span><span class="token punctuation">:</span>
        text <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
        images <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
        <span class="token comment" spellcheck="true"># Load all the files and order them</span>
        all_filenames <span class="token operator">=</span> listdir<span class="token punctuation">(</span>data_dir<span class="token punctuation">)</span>
        all_filenames<span class="token punctuation">.</span>sort<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token keyword">for</span> filename <span class="token keyword">in</span> <span class="token punctuation">(</span>all_filenames<span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token keyword">if</span> filename<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">3</span><span class="token punctuation">:</span><span class="token punctuation">]</span> <span class="token operator">==</span> <span class="token string">"npz"</span><span class="token punctuation">:</span>
                <span class="token comment" spellcheck="true"># Load the images already prepared in arrays</span>
                image <span class="token operator">=</span> np<span class="token punctuation">.</span>load<span class="token punctuation">(</span>data_dir<span class="token operator">+</span>filename<span class="token punctuation">)</span>
                images<span class="token punctuation">.</span>append<span class="token punctuation">(</span>image<span class="token punctuation">[</span><span class="token string">'features'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
            <span class="token keyword">else</span><span class="token punctuation">:</span>
                <span class="token comment" spellcheck="true"># Load the boostrap tokens and rap them in a start and end tag</span>
                syntax <span class="token operator">=</span> <span class="token string">'&lt;START&gt; '</span> <span class="token operator">+</span> load_doc<span class="token punctuation">(</span>data_dir<span class="token operator">+</span>filename<span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token string">' &lt;END&gt;'</span>
                <span class="token comment" spellcheck="true"># Seperate all the words with a single space</span>
                syntax <span class="token operator">=</span> <span class="token string">' '</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span>syntax<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
                <span class="token comment" spellcheck="true"># Add a space after each comma</span>
                syntax <span class="token operator">=</span> syntax<span class="token punctuation">.</span>replace<span class="token punctuation">(</span><span class="token string">','</span><span class="token punctuation">,</span> <span class="token string">' ,'</span><span class="token punctuation">)</span>
                text<span class="token punctuation">.</span>append<span class="token punctuation">(</span>syntax<span class="token punctuation">)</span>
        images <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>images<span class="token punctuation">,</span> dtype<span class="token operator">=</span>float<span class="token punctuation">)</span>
        <span class="token keyword">return</span> images<span class="token punctuation">,</span> text
    
    train_features<span class="token punctuation">,</span> texts <span class="token operator">=</span> load_data<span class="token punctuation">(</span>dir_name<span class="token punctuation">)</span>
    
    <span class="token comment" spellcheck="true"># Initialize the function to create the vocabulary </span>
    tokenizer <span class="token operator">=</span> Tokenizer<span class="token punctuation">(</span>filters<span class="token operator">=</span><span class="token string">''</span><span class="token punctuation">,</span> split<span class="token operator">=</span><span class="token string">" "</span><span class="token punctuation">,</span> lower<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
    <span class="token comment" spellcheck="true"># Create the vocabulary </span>
    tokenizer<span class="token punctuation">.</span>fit_on_texts<span class="token punctuation">(</span><span class="token punctuation">[</span>load_doc<span class="token punctuation">(</span><span class="token string">'bootstrap.vocab'</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    
    <span class="token comment" spellcheck="true"># Add one spot for the empty word in the vocabulary </span>
    vocab_size <span class="token operator">=</span> len<span class="token punctuation">(</span>tokenizer<span class="token punctuation">.</span>word_index<span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token number">1</span>
    <span class="token comment" spellcheck="true"># Map the input sentences into the vocabulary indexes</span>
    train_sequences <span class="token operator">=</span> tokenizer<span class="token punctuation">.</span>texts_to_sequences<span class="token punctuation">(</span>texts<span class="token punctuation">)</span>
    <span class="token comment" spellcheck="true"># The longest set of boostrap tokens</span>
    max_sequence <span class="token operator">=</span> max<span class="token punctuation">(</span>len<span class="token punctuation">(</span>s<span class="token punctuation">)</span> <span class="token keyword">for</span> s <span class="token keyword">in</span> train_sequences<span class="token punctuation">)</span>
    <span class="token comment" spellcheck="true"># Specify how many tokens to have in each input sentence</span>
    max_length <span class="token operator">=</span> <span class="token number">48</span>
    
    <span class="token keyword">def</span> <span class="token function">preprocess_data</span><span class="token punctuation">(</span>sequences<span class="token punctuation">,</span> features<span class="token punctuation">)</span><span class="token punctuation">:</span>
        X<span class="token punctuation">,</span> y<span class="token punctuation">,</span> image_data <span class="token operator">=</span> list<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> list<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> list<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token keyword">for</span> img_no<span class="token punctuation">,</span> seq <span class="token keyword">in</span> enumerate<span class="token punctuation">(</span>sequences<span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> len<span class="token punctuation">(</span>seq<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
                <span class="token comment" spellcheck="true"># Add the sentence until the current count(i) and add the current count to the output</span>
                in_seq<span class="token punctuation">,</span> out_seq <span class="token operator">=</span> seq<span class="token punctuation">[</span><span class="token punctuation">:</span>i<span class="token punctuation">]</span><span class="token punctuation">,</span> seq<span class="token punctuation">[</span>i<span class="token punctuation">]</span>
                <span class="token comment" spellcheck="true"># Pad all the input token sentences to max_sequence</span>
                in_seq <span class="token operator">=</span> pad_sequences<span class="token punctuation">(</span><span class="token punctuation">[</span>in_seq<span class="token punctuation">]</span><span class="token punctuation">,</span> maxlen<span class="token operator">=</span>max_sequence<span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
                <span class="token comment" spellcheck="true"># Turn the output into one-hot encoding</span>
                out_seq <span class="token operator">=</span> to_categorical<span class="token punctuation">(</span><span class="token punctuation">[</span>out_seq<span class="token punctuation">]</span><span class="token punctuation">,</span> num_classes<span class="token operator">=</span>vocab_size<span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
                <span class="token comment" spellcheck="true"># Add the corresponding image to the boostrap token file</span>
                image_data<span class="token punctuation">.</span>append<span class="token punctuation">(</span>features<span class="token punctuation">[</span>img_no<span class="token punctuation">]</span><span class="token punctuation">)</span>
                <span class="token comment" spellcheck="true"># Cap the input sentence to 48 tokens and add it</span>
                X<span class="token punctuation">.</span>append<span class="token punctuation">(</span>in_seq<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">48</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
                y<span class="token punctuation">.</span>append<span class="token punctuation">(</span>out_seq<span class="token punctuation">)</span>
        <span class="token keyword">return</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>X<span class="token punctuation">)</span><span class="token punctuation">,</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>y<span class="token punctuation">)</span><span class="token punctuation">,</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>image_data<span class="token punctuation">)</span>
    
    X<span class="token punctuation">,</span> y<span class="token punctuation">,</span> image_data <span class="token operator">=</span> preprocess_data<span class="token punctuation">(</span>train_sequences<span class="token punctuation">,</span> train_features<span class="token punctuation">)</span>
    
    <span class="token comment" spellcheck="true">#Create the encoder</span>
    image_model <span class="token operator">=</span> Sequential<span class="token punctuation">(</span><span class="token punctuation">)</span>
    image_model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>Conv2D<span class="token punctuation">(</span><span class="token number">16</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token string">'valid'</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">'relu'</span><span class="token punctuation">,</span> input_shape<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    image_model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>Conv2D<span class="token punctuation">(</span><span class="token number">16</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">'relu'</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token string">'same'</span><span class="token punctuation">,</span> strides<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    image_model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>Conv2D<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">'relu'</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token string">'same'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    image_model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>Conv2D<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">'relu'</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token string">'same'</span><span class="token punctuation">,</span> strides<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    image_model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>Conv2D<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">'relu'</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token string">'same'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    image_model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>Conv2D<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">'relu'</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token string">'same'</span><span class="token punctuation">,</span> strides<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    image_model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>Conv2D<span class="token punctuation">(</span><span class="token number">128</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">'relu'</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token string">'same'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    
    image_model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>Flatten<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    image_model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>Dense<span class="token punctuation">(</span><span class="token number">1024</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">'relu'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    image_model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>Dropout<span class="token punctuation">(</span><span class="token number">0.3</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    image_model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>Dense<span class="token punctuation">(</span><span class="token number">1024</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">'relu'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    image_model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>Dropout<span class="token punctuation">(</span><span class="token number">0.3</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    
    image_model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>RepeatVector<span class="token punctuation">(</span>max_length<span class="token punctuation">)</span><span class="token punctuation">)</span>
    
    visual_input <span class="token operator">=</span> Input<span class="token punctuation">(</span>shape<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    encoded_image <span class="token operator">=</span> image_model<span class="token punctuation">(</span>visual_input<span class="token punctuation">)</span>
    
    language_input <span class="token operator">=</span> Input<span class="token punctuation">(</span>shape<span class="token operator">=</span><span class="token punctuation">(</span>max_length<span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    language_model <span class="token operator">=</span> Embedding<span class="token punctuation">(</span>vocab_size<span class="token punctuation">,</span> <span class="token number">50</span><span class="token punctuation">,</span> input_length<span class="token operator">=</span>max_length<span class="token punctuation">,</span> mask_zero<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">(</span>language_input<span class="token punctuation">)</span>
    language_model <span class="token operator">=</span> LSTM<span class="token punctuation">(</span><span class="token number">128</span><span class="token punctuation">,</span> return_sequences<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">(</span>language_model<span class="token punctuation">)</span>
    language_model <span class="token operator">=</span> LSTM<span class="token punctuation">(</span><span class="token number">128</span><span class="token punctuation">,</span> return_sequences<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">(</span>language_model<span class="token punctuation">)</span>
    
    <span class="token comment" spellcheck="true">#Create the decoder</span>
    decoder <span class="token operator">=</span> concatenate<span class="token punctuation">(</span><span class="token punctuation">[</span>encoded_image<span class="token punctuation">,</span> language_model<span class="token punctuation">]</span><span class="token punctuation">)</span>
    decoder <span class="token operator">=</span> LSTM<span class="token punctuation">(</span><span class="token number">512</span><span class="token punctuation">,</span> return_sequences<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">(</span>decoder<span class="token punctuation">)</span>
    decoder <span class="token operator">=</span> LSTM<span class="token punctuation">(</span><span class="token number">512</span><span class="token punctuation">,</span> return_sequences<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">(</span>decoder<span class="token punctuation">)</span>
    decoder <span class="token operator">=</span> Dense<span class="token punctuation">(</span>vocab_size<span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">'softmax'</span><span class="token punctuation">)</span><span class="token punctuation">(</span>decoder<span class="token punctuation">)</span>
    
    <span class="token comment" spellcheck="true"># Compile the model</span>
    model <span class="token operator">=</span> Model<span class="token punctuation">(</span>inputs<span class="token operator">=</span><span class="token punctuation">[</span>visual_input<span class="token punctuation">,</span> language_input<span class="token punctuation">]</span><span class="token punctuation">,</span> outputs<span class="token operator">=</span>decoder<span class="token punctuation">)</span>
    optimizer <span class="token operator">=</span> RMSprop<span class="token punctuation">(</span>lr<span class="token operator">=</span><span class="token number">0.0001</span><span class="token punctuation">,</span> clipvalue<span class="token operator">=</span><span class="token number">1.0</span><span class="token punctuation">)</span>
    model<span class="token punctuation">.</span>compile<span class="token punctuation">(</span>loss<span class="token operator">=</span><span class="token string">'categorical_crossentropy'</span><span class="token punctuation">,</span> optimizer<span class="token operator">=</span>optimizer<span class="token punctuation">)</span>
    
    <span class="token comment" spellcheck="true">#Save the model for every 2nd epoch</span>
    filepath<span class="token operator">=</span><span class="token string">"org-weights-epoch-{epoch:04d}--val_loss-{val_loss:.4f}--loss-{loss:.4f}.hdf5"</span>
    checkpoint <span class="token operator">=</span> ModelCheckpoint<span class="token punctuation">(</span>filepath<span class="token punctuation">,</span> monitor<span class="token operator">=</span><span class="token string">'val_loss'</span><span class="token punctuation">,</span> verbose<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> save_weights_only<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> period<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>
    callbacks_list <span class="token operator">=</span> <span class="token punctuation">[</span>checkpoint<span class="token punctuation">]</span>
    
    <span class="token comment" spellcheck="true"># Train the model</span>
    model<span class="token punctuation">.</span>fit<span class="token punctuation">(</span><span class="token punctuation">[</span>image_data<span class="token punctuation">,</span> X<span class="token punctuation">]</span><span class="token punctuation">,</span> y<span class="token punctuation">,</span> batch_size<span class="token operator">=</span><span class="token number">64</span><span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> validation_split<span class="token operator">=</span><span class="token number">0.1</span><span class="token punctuation">,</span> callbacks<span class="token operator">=</span>callbacks_list<span class="token punctuation">,</span> verbose<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> epochs<span class="token operator">=</span><span class="token number">50</span><span class="token punctuation">)</span>
</code></pre>
      </div>
<h3>Test accuracy</h3>
<p>It’s tricky to find a fair way to measure the accuracy. Say you compare word by word. If your prediction is one word out of sync, you might have 0% accuracy. If you remove one word which syncs the prediction, you might end up with 99/100.</p>
<p>I used the BLEU score, best practice in machine translating and image captioning models. It breaks the sentence into four n-grams, from 1-4 word sequences. In the below prediction “cat” is supposed to be “code”. </p>

  <a class="gatsby-resp-image-link" href="https://blog.floydhub.com/static/bleu_score-741cd6ede6d32df1de54a6d8dd41c530-ef96e.png" style="display: block" target="_blank" rel="noopener">
  
  <span class="gatsby-resp-image-wrapper" style="position: relative; display: block; ; max-width: 768px; margin-left: auto; margin-right: auto;">
    <span class="gatsby-resp-image-background-image" style="padding-bottom: 13.28125%; position: relative; bottom: 0; left: 0; background-image: url(&#39;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAADCAYAAACTWi8uAAAACXBIWXMAAAsSAAALEgHS3X78AAAAi0lEQVQI132MSw6CMAAFuf/5ulGjiSDQ0vIppWhLYSSuiCZOMouXTF7GgZQSUkom53DpiV08Ns28/ISfHY3v0UYze//pt23jm+w4/B4KIdCNRsaBMvY00WJ7Q7iXpFvJdi6YxZXidKGq6/+HIQTyPMeOI8swkrqBpd01HUnvqpYoDd2jQinFuq4/h29P6egMp9udTQAAAABJRU5ErkJggg==&#39;); background-size: cover; display: block;">
      <img class="gatsby-resp-image-image" style="width: 100%; height: 100%; margin: 0; vertical-align: middle; position: absolute; top: 0; left: 0; box-shadow: inset 0px 0px 0px 400px white;" alt="bleu score" title="" src="./Turning Design Mockups Into Code With Deep Learning - FloydHub Blog_files/bleu_score-741cd6ede6d32df1de54a6d8dd41c530-6c1a3.png" srcset="/static/bleu_score-741cd6ede6d32df1de54a6d8dd41c530-4f362.png 192w,
/static/bleu_score-741cd6ede6d32df1de54a6d8dd41c530-1883a.png 384w,
/static/bleu_score-741cd6ede6d32df1de54a6d8dd41c530-6c1a3.png 768w,
/static/bleu_score-741cd6ede6d32df1de54a6d8dd41c530-650d4.png 1152w,
/static/bleu_score-741cd6ede6d32df1de54a6d8dd41c530-bbf5a.png 1536w,
/static/bleu_score-741cd6ede6d32df1de54a6d8dd41c530-c6553.png 2304w,
/static/bleu_score-741cd6ede6d32df1de54a6d8dd41c530-ef96e.png 3840w" sizes="(max-width: 768px) 100vw, 768px">
    </span>
  </span>
  
  </a>
    
<br>
<p>To get the final score you multiply each score with 25%, (4/5) * 0.25 + (2/4) * 0.25 + (1/3) * 0.25 + (0/2) * 0.25 = 0.2 + 0.125 + 0.083 + 0 = 0.408 . The sum is then multiplied with a sentence length penalty. Since the length is correct in our example, it becomes our final score. </p>
<p>You could increase the number of n-grams to make it harder. A four n-gram model is the model that best corresponds to human translations. I’d recommend running a few examples with the below code and reading the <a href="https://en.wikipedia.org/wiki/BLEU">wiki page.</a> </p>
<div class="gatsby-highlight">
      <pre class="language-python"><code>    <span class="token comment" spellcheck="true">#Create a function to read a file and return its content</span>
    <span class="token keyword">def</span> <span class="token function">load_doc</span><span class="token punctuation">(</span>filename<span class="token punctuation">)</span><span class="token punctuation">:</span>
        file <span class="token operator">=</span> open<span class="token punctuation">(</span>filename<span class="token punctuation">,</span> <span class="token string">'r'</span><span class="token punctuation">)</span>
        text <span class="token operator">=</span> file<span class="token punctuation">.</span>read<span class="token punctuation">(</span><span class="token punctuation">)</span>
        file<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token keyword">return</span> text
    
    <span class="token keyword">def</span> <span class="token function">load_data</span><span class="token punctuation">(</span>data_dir<span class="token punctuation">)</span><span class="token punctuation">:</span>
        text <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
        images <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
        files_in_folder <span class="token operator">=</span> os<span class="token punctuation">.</span>listdir<span class="token punctuation">(</span>data_dir<span class="token punctuation">)</span>
        files_in_folder<span class="token punctuation">.</span>sort<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token keyword">for</span> filename <span class="token keyword">in</span> tqdm<span class="token punctuation">(</span>files_in_folder<span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token comment" spellcheck="true">#Add an image</span>
            <span class="token keyword">if</span> filename<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">3</span><span class="token punctuation">:</span><span class="token punctuation">]</span> <span class="token operator">==</span> <span class="token string">"npz"</span><span class="token punctuation">:</span>
                image <span class="token operator">=</span> np<span class="token punctuation">.</span>load<span class="token punctuation">(</span>data_dir<span class="token operator">+</span>filename<span class="token punctuation">)</span>
                images<span class="token punctuation">.</span>append<span class="token punctuation">(</span>image<span class="token punctuation">[</span><span class="token string">'features'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
            <span class="token keyword">else</span><span class="token punctuation">:</span>
            <span class="token comment" spellcheck="true"># Add text and wrap it in a start and end tag</span>
                syntax <span class="token operator">=</span> <span class="token string">'&lt;START&gt; '</span> <span class="token operator">+</span> load_doc<span class="token punctuation">(</span>data_dir<span class="token operator">+</span>filename<span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token string">' &lt;END&gt;'</span>
                <span class="token comment" spellcheck="true">#Seperate each word with a space</span>
                syntax <span class="token operator">=</span> <span class="token string">' '</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span>syntax<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
                <span class="token comment" spellcheck="true">#Add a space between each comma</span>
                syntax <span class="token operator">=</span> syntax<span class="token punctuation">.</span>replace<span class="token punctuation">(</span><span class="token string">','</span><span class="token punctuation">,</span> <span class="token string">' ,'</span><span class="token punctuation">)</span>
                text<span class="token punctuation">.</span>append<span class="token punctuation">(</span>syntax<span class="token punctuation">)</span>
        images <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>images<span class="token punctuation">,</span> dtype<span class="token operator">=</span>float<span class="token punctuation">)</span>
        <span class="token keyword">return</span> images<span class="token punctuation">,</span> text
    
    <span class="token comment" spellcheck="true">#Intialize the function to create the vocabulary</span>
    tokenizer <span class="token operator">=</span> Tokenizer<span class="token punctuation">(</span>filters<span class="token operator">=</span><span class="token string">''</span><span class="token punctuation">,</span> split<span class="token operator">=</span><span class="token string">" "</span><span class="token punctuation">,</span> lower<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
    <span class="token comment" spellcheck="true">#Create the vocabulary in a specific order</span>
    tokenizer<span class="token punctuation">.</span>fit_on_texts<span class="token punctuation">(</span><span class="token punctuation">[</span>load_doc<span class="token punctuation">(</span><span class="token string">'bootstrap.vocab'</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    
    dir_name <span class="token operator">=</span> <span class="token string">'../../../../eval/'</span>
    train_features<span class="token punctuation">,</span> texts <span class="token operator">=</span> load_data<span class="token punctuation">(</span>dir_name<span class="token punctuation">)</span>
    
    <span class="token comment" spellcheck="true">#load model and weights </span>
    json_file <span class="token operator">=</span> open<span class="token punctuation">(</span><span class="token string">'../../../../model.json'</span><span class="token punctuation">,</span> <span class="token string">'r'</span><span class="token punctuation">)</span>
    loaded_model_json <span class="token operator">=</span> json_file<span class="token punctuation">.</span>read<span class="token punctuation">(</span><span class="token punctuation">)</span>
    json_file<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span>
    loaded_model <span class="token operator">=</span> model_from_json<span class="token punctuation">(</span>loaded_model_json<span class="token punctuation">)</span>
    <span class="token comment" spellcheck="true"># load weights into new model</span>
    loaded_model<span class="token punctuation">.</span>load_weights<span class="token punctuation">(</span><span class="token string">"../../../../weights.hdf5"</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Loaded model from disk"</span><span class="token punctuation">)</span>
    
    <span class="token comment" spellcheck="true"># map an integer to a word</span>
    <span class="token keyword">def</span> <span class="token function">word_for_id</span><span class="token punctuation">(</span>integer<span class="token punctuation">,</span> tokenizer<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">for</span> word<span class="token punctuation">,</span> index <span class="token keyword">in</span> tokenizer<span class="token punctuation">.</span>word_index<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token keyword">if</span> index <span class="token operator">==</span> integer<span class="token punctuation">:</span>
                <span class="token keyword">return</span> word
        <span class="token keyword">return</span> None
    <span class="token keyword">print</span><span class="token punctuation">(</span>word_for_id<span class="token punctuation">(</span><span class="token number">17</span><span class="token punctuation">,</span> tokenizer<span class="token punctuation">)</span><span class="token punctuation">)</span>
    
    <span class="token comment" spellcheck="true"># generate a description for an image</span>
    <span class="token keyword">def</span> <span class="token function">generate_desc</span><span class="token punctuation">(</span>model<span class="token punctuation">,</span> tokenizer<span class="token punctuation">,</span> photo<span class="token punctuation">,</span> max_length<span class="token punctuation">)</span><span class="token punctuation">:</span>
        photo <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span>photo<span class="token punctuation">]</span><span class="token punctuation">)</span>
        <span class="token comment" spellcheck="true"># seed the generation process</span>
        in_text <span class="token operator">=</span> <span class="token string">'&lt;START&gt; '</span>
        <span class="token comment" spellcheck="true"># iterate over the whole length of the sequence</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'\nPrediction----&gt;\n\n&lt;START&gt; '</span><span class="token punctuation">,</span> end<span class="token operator">=</span><span class="token string">''</span><span class="token punctuation">)</span>
        <span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">150</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token comment" spellcheck="true"># integer encode input sequence</span>
            sequence <span class="token operator">=</span> tokenizer<span class="token punctuation">.</span>texts_to_sequences<span class="token punctuation">(</span><span class="token punctuation">[</span>in_text<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
            <span class="token comment" spellcheck="true"># pad input</span>
            sequence <span class="token operator">=</span> pad_sequences<span class="token punctuation">(</span><span class="token punctuation">[</span>sequence<span class="token punctuation">]</span><span class="token punctuation">,</span> maxlen<span class="token operator">=</span>max_length<span class="token punctuation">)</span>
            <span class="token comment" spellcheck="true"># predict next word</span>
            yhat <span class="token operator">=</span> loaded_model<span class="token punctuation">.</span>predict<span class="token punctuation">(</span><span class="token punctuation">[</span>photo<span class="token punctuation">,</span> sequence<span class="token punctuation">]</span><span class="token punctuation">,</span> verbose<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
            <span class="token comment" spellcheck="true"># convert probability to integer</span>
            yhat <span class="token operator">=</span> argmax<span class="token punctuation">(</span>yhat<span class="token punctuation">)</span>
            <span class="token comment" spellcheck="true"># map integer to word</span>
            word <span class="token operator">=</span> word_for_id<span class="token punctuation">(</span>yhat<span class="token punctuation">,</span> tokenizer<span class="token punctuation">)</span>
            <span class="token comment" spellcheck="true"># stop if we cannot map the word</span>
            <span class="token keyword">if</span> word <span class="token keyword">is</span> None<span class="token punctuation">:</span>
                <span class="token keyword">break</span>
            <span class="token comment" spellcheck="true"># append as input for generating the next word</span>
            in_text <span class="token operator">+=</span> word <span class="token operator">+</span> <span class="token string">' '</span>
            <span class="token comment" spellcheck="true"># stop if we predict the end of the sequence</span>
            <span class="token keyword">print</span><span class="token punctuation">(</span>word <span class="token operator">+</span> <span class="token string">' '</span><span class="token punctuation">,</span> end<span class="token operator">=</span><span class="token string">''</span><span class="token punctuation">)</span>
            <span class="token keyword">if</span> word <span class="token operator">==</span> <span class="token string">'&lt;END&gt;'</span><span class="token punctuation">:</span>
                <span class="token keyword">break</span>
        <span class="token keyword">return</span> in_text
        
    
    max_length <span class="token operator">=</span> <span class="token number">48</span> 
    
    <span class="token comment" spellcheck="true"># evaluate the skill of the model</span>
    <span class="token keyword">def</span> <span class="token function">evaluate_model</span><span class="token punctuation">(</span>model<span class="token punctuation">,</span> descriptions<span class="token punctuation">,</span> photos<span class="token punctuation">,</span> tokenizer<span class="token punctuation">,</span> max_length<span class="token punctuation">)</span><span class="token punctuation">:</span>
        actual<span class="token punctuation">,</span> predicted <span class="token operator">=</span> list<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> list<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token comment" spellcheck="true"># step over the whole set</span>
        <span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span>len<span class="token punctuation">(</span>texts<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            yhat <span class="token operator">=</span> generate_desc<span class="token punctuation">(</span>model<span class="token punctuation">,</span> tokenizer<span class="token punctuation">,</span> photos<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">,</span> max_length<span class="token punctuation">)</span>
            <span class="token comment" spellcheck="true"># store actual and predicted</span>
            <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'\n\nReal----&gt;\n\n'</span> <span class="token operator">+</span> texts<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span>
            actual<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token punctuation">[</span>texts<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
            predicted<span class="token punctuation">.</span>append<span class="token punctuation">(</span>yhat<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token comment" spellcheck="true"># calculate BLEU score</span>
        bleu <span class="token operator">=</span> corpus_bleu<span class="token punctuation">(</span>actual<span class="token punctuation">,</span> predicted<span class="token punctuation">)</span>
        <span class="token keyword">return</span> bleu<span class="token punctuation">,</span> actual<span class="token punctuation">,</span> predicted
    
    bleu<span class="token punctuation">,</span> actual<span class="token punctuation">,</span> predicted <span class="token operator">=</span> evaluate_model<span class="token punctuation">(</span>loaded_model<span class="token punctuation">,</span> texts<span class="token punctuation">,</span> train_features<span class="token punctuation">,</span> tokenizer<span class="token punctuation">,</span> max_length<span class="token punctuation">)</span>
    
    <span class="token comment" spellcheck="true">#Compile the tokens into HTML and css</span>
    dsl_path <span class="token operator">=</span> <span class="token string">"compiler/assets/web-dsl-mapping.json"</span>
    compiler <span class="token operator">=</span> Compiler<span class="token punctuation">(</span>dsl_path<span class="token punctuation">)</span>
    compiled_website <span class="token operator">=</span> compiler<span class="token punctuation">.</span>compile<span class="token punctuation">(</span>predicted<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token string">'index.html'</span><span class="token punctuation">)</span>
    
    <span class="token keyword">print</span><span class="token punctuation">(</span>compiled_website <span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>bleu<span class="token punctuation">)</span>
</code></pre>
      </div>
<h3>Output</h3>

  <a class="gatsby-resp-image-link" href="https://blog.floydhub.com/static/bootstrap_output-8a1b036ddc436e20453b7c2962b0fa85-1b912.png" style="display: block" target="_blank" rel="noopener">
  
  <span class="gatsby-resp-image-wrapper" style="position: relative; display: block; ; max-width: 768px; margin-left: auto; margin-right: auto;">
    <span class="gatsby-resp-image-background-image" style="padding-bottom: 35.75909661229611%; position: relative; bottom: 0; left: 0; background-image: url(&#39;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAHCAYAAAAIy204AAAACXBIWXMAAAsSAAALEgHS3X78AAABHklEQVQoz3VRy27CMBDM/39W1UsvVSMa0qIAgYoG7MTvPJVo6l0JVNRyGMmeXc/ujJO+7+G8g3UWIQQMw8Agvm27iJbPITgoo2GMQdM0sNbCOcdolEIdOa0NksPhiOfXNS46YJqmh5BS4unlDeXFPuyh4Yk7V6h3W55IG3Zd9wfjOMJrBZnn3Oe9/7eP+MScTjdBIshedszYGtm5CtpoSXzcC4rsne/US9uxoK4qnMs9dMxnXa6ZXO1WnIc45lC14ExtzOl788lDsn0W6xqbrw1kLdFUJUR14FrS00dEdd6itTxZOcWZjK2J/MC1QFtFERJXXnGfNJIdDfHd0HmOLJnn+S7YU4yAPuA3tywLWxJC3FAUBdI0RRUdXjmy/wPUCBV9VdCiYgAAAABJRU5ErkJggg==&#39;); background-size: cover; display: block;">
      <img class="gatsby-resp-image-image" style="width: 100%; height: 100%; margin: 0; vertical-align: middle; position: absolute; top: 0; left: 0; box-shadow: inset 0px 0px 0px 400px white;" alt="bootstrap output" title="" src="./Turning Design Mockups Into Code With Deep Learning - FloydHub Blog_files/bootstrap_output-8a1b036ddc436e20453b7c2962b0fa85-6c1a3.png" srcset="/static/bootstrap_output-8a1b036ddc436e20453b7c2962b0fa85-4f362.png 192w,
/static/bootstrap_output-8a1b036ddc436e20453b7c2962b0fa85-1883a.png 384w,
/static/bootstrap_output-8a1b036ddc436e20453b7c2962b0fa85-6c1a3.png 768w,
/static/bootstrap_output-8a1b036ddc436e20453b7c2962b0fa85-650d4.png 1152w,
/static/bootstrap_output-8a1b036ddc436e20453b7c2962b0fa85-bbf5a.png 1536w,
/static/bootstrap_output-8a1b036ddc436e20453b7c2962b0fa85-c6553.png 2304w,
/static/bootstrap_output-8a1b036ddc436e20453b7c2962b0fa85-1b912.png 3188w" sizes="(max-width: 768px) 100vw, 768px">
    </span>
  </span>
  
  </a>
    
<h5>Links to sample output</h5>
<ul>
<li><a href="https://emilwallner.github.io/bootstrap/pred_1/">Generated website 1</a> - <a href="https://emilwallner.github.io/bootstrap/real_1/">Original 1</a></li>
<li><a href="https://emilwallner.github.io/bootstrap/pred_2/">Generated website 2</a> - <a href="https://emilwallner.github.io/bootstrap/real_2/">Original 2</a></li>
<li><a href="https://emilwallner.github.io/bootstrap/pred_3/">Generated website 3</a> - <a href="https://emilwallner.github.io/bootstrap/real_3/">Original 3</a></li>
<li><a href="https://emilwallner.github.io/bootstrap/pred_4/">Generated website 4</a> - <a href="https://emilwallner.github.io/bootstrap/real_4/">Original 4</a></li>
<li><a href="https://emilwallner.github.io/bootstrap/pred_5/">Generated website 5</a> - <a href="https://emilwallner.github.io/bootstrap/real_5/">Original 5</a></li>
</ul>
<h3>Mistakes I made:</h3>
<ul>
<li><strong>Understand the weakness of the models instead of testing random models.</strong> First I applied random things such as batch normalization, bidirectional networks and tried implementing attention. After looking at the test data and seeing that it could not predict color and position with high accuracy I realized there was a weakness in the CNN. This lead me to replace maxpooling with increased strides. The validation loss went from 0.12 to 0.02 and increased the BLEU score from 85% to 97%. </li>
<li><strong>Only use pre-trained models if they are relevant.</strong> Given the small dataset I thought that a pre-trained image model would improve the performance. From my experiments, and end-to-end model is slower to train and requires more memory, but is 30% more accurate. </li>
<li><strong>Plan for slight variance when you run your model on a remote server.</strong> On my mac, it read the files in alphabetic order. However, on the server, it was randomly located. This created a mismatch between the screenshots and the code. It still converged, but was the validation data was 50% worse than when I fixed it. </li>
<li><strong>Make sure you understand library functions.</strong> Include space for the empty token in your vocabulary. When I didn’t add it, it did not include one of the tokens. I only noticed it after looking at the final output several times and noticing that it never predicted a “single” token. After a quick check, I realized it wasn’t even in the vocabulary. Also, use the same order in the vocabulary for training and testing.</li>
<li><strong>Use lighter models when experimenting.</strong> Using GRUs instead of LSTMs reduced each epoch cycle by 30%, and did not have a large effect on the performance. </li>
</ul>
<h2>Next steps</h2>
<p>Front-end development is an ideal space to apply deep learning. It’s easy to generate data and the current deep learning algorithms can map most of the logic. </p>
<p>One of the most exciting areas is <a href="https://arxiv.org/pdf/1502.03044.pdf">applying attention to LSTMs</a>. This will not just improve the accuracy, but enable us to visualize where the CNN puts its focus as it generates the markup.  </p>
<p>Attention is also key for communicating between markup, stylesheets, scripts and eventually the backend. Attention layers can keep track of variables, enabling the network to communicate between programming languages. </p>
<p>But in the near feature, the biggest impact will come from building a scalable way to synthesize data. Then you can add fonts, colors, words, and animations step-by-step.</p>
<p>So far, most progress is happening in taking sketches and turning them into template apps. In less then two years, we’ll be able to draw an app on paper and have the corresponding front-end in less than a second. There are already two working prototypes built by <a href="https://airbnb.design/sketching-interfaces/">Airbnb’s design team</a> and <a href="https://www.uizard.io/">Uizard</a>. </p>
<p>Here are some experiments to get started.  </p>
<h2>Experiments</h2>
<h5>Getting started</h5>
<ul>
<li>Run all the models</li>
<li>Try different hyper parameters </li>
<li>Test a different CNN architecture </li>
<li>Add Bidirectional LSTM models</li>
<li>Implement the model with a <a href="http://lstm.seas.harvard.edu/latex/">different dataset</a>. (You can easily mount this dataset in your FloydHub jobs with this flag <code>--data emilwallner/datasets/100k-html:data</code>)</li>
</ul>
<h5>Further experiments</h5>
<ul>
<li>Creating a solid random app/web generator with the corresponding syntax. </li>
<li>Data for a sketch to app model. Auto-convert the app/web screenshots into sketches and use a GAN to create variety. </li>
<li>Apply an attention layer to visualize the focus on the image for each prediction, <a href="https://arxiv.org/abs/1502.03044">similar to this model</a>. </li>
<li>Create a framework for a modular approach. Say, having encoder models for fonts, one for color, another for layout and combine them with one decoder. A good start could be solid image features. </li>
<li>Feed the network simple HTML components and teach it to generate animations using CSS. It would be fascinating to have an attention approach and visualize the focus on both input sources.</li>
</ul>
<p><strong>Huge thanks to</strong> Tony Beltramelli and Jon Gold for answering questions, their research, and all their ideas. Thanks to Jason Brownlee for his stellar Keras tutorials, I included a few snippets from his tutorial in the core Keras implementation, and Beltramelli for providing the data. Also thanks to Qingping Hou, Charlie Harrington, Sai Soundararaj, Jannes Klaas, Claudio Cabral, Alain Demenet and Dylan Djian for reading drafts of this. </p>
<hr>
<h2>About Emil Wallner</h2>
<p>This the fourth part of a multi-part blog series from Emil as he learns deep learning. Emil has spent a decade exploring human learning. He's worked for Oxford's business school, invested in education startups, and built an education technology business. Last year, he enrolled at <a href="https://twitter.com/paulg/status/847844863727087616">Ecole 42</a> to apply his knowledge of human learning to machine learning.</p>
<p>You can follow along with Emil on <a href="https://twitter.com/EmilWallner">Twitter</a> and <a href="https://medium.com/@emilwallner">Medium</a>.</p></div><div class="blog-post-content" style="margin-left:auto;margin-right:auto;max-width:768px;" data-reactid="42"></div><div style="text-align:center;margin-left:auto;margin-right:auto;max-width:768px;" data-reactid="43"><hr data-reactid="44"><p data-reactid="45"><!-- react-text: 46 -->Start running GPU-powered Jupyter Notebooks.<!-- /react-text --><!-- react-text: 47 --> <!-- /react-text --><a href="https://www.floydhub.com/pricing?utm_source=turning-design-mockups-into-code-with-deep-learning&amp;utm_medium=blog&amp;utm_campaign=base_n17" data-reactid="48">Sign up today for a free 2-hour GPU Powerup.</a></p></div></div></div></div></div></div><script>
  
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-90905407-1', 'auto');
  </script></body></html>